{"id": "0", "title": "Word Frequency Counter", "description": "Given a file path, create a function `word_count` that reads the file, counts the occurrences of each word, and returns a dictionary containing the word counts.  The function should perform the following steps:", "language": "python", "difficulty": "medium", "category": "Algorithm and Data Structure", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nCreate a function named `word_count` that takes a file path as an argument, reads the file content, and counts the number of times each word appears in the file. The function should return a dictionary where the keys are the words and the values are the number of times that word appears in the file. It should ignore case and remove punctuation. Finally, the dictionary items should be sorted in descending order by the number of times the word appears. If multiple words appear the same number of times, they should be sorted in ascending alphabetical order. The function does not need to handle the case where the file does not exist.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testword_count:\n    def test_word_count_basic_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_basic.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"This is a basic test file with some common words.\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'this': 1\\n'is': 1\\n'a': 1\\n'basic': 1\\n'test': 1\\n'file': 1\\n'with': 1\\n'some': 1\\n'common': 1\\n'words': 1\\n\" in captured.out\n\n\n", "llm_code": "import string\n\ndef word_count(file_path):\n    \"\"\"\n    Counts the number of times each word appears in a file.\n\n    Args:\n        file_path (str): The path to the file.\n\n    Returns:\n        dict: A dictionary where the keys are the words and the values are the\n              number of times that word appears in the file. The dictionary is\n              sorted in descending order by the number of times the word\n              appears. If multiple words appear the same number of times, they\n              are sorted in ascending alphabetical order.\n    \"\"\"\n    word_counts = {}\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            line = line.strip().lower()\n            for char in string.punctuation:\n                line = line.replace(char, '')\n            words = line.split()\n            for word in words:\n                if word:\n                    word_counts[word] = word_counts.get(word, 0) + 1\n\n    sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: (-item[1], item[0])))\n\n    return sorted_word_counts", "correct_code": "import string\nfrom collections import Counter\n\n\ndef word_count(file_path):\n    try:\n        # \u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n\n        # \u79fb\u9664\u6807\u70b9\u7b26\u53f7\u5e76\u8f6c\u6362\u4e3a\u5c0f\u5199\n        translator = str.maketrans(\"\", \"\", string.punctuation)\n        content = content.translate(translator).lower()\n\n        # \u4f7f\u7528 Counter \u7edf\u8ba1\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\n        words = content.split()\n        word_counter = Counter(words)\n\n        # \u6309\u7167\u51fa\u73b0\u6b21\u6570\u964d\u5e8f\u6392\u5217\n        sorted_word_count = sorted(word_counter.items(), key=lambda x: x[1], reverse=True)\n\n        for word, count in sorted_word_count:\n            print(f\"'{word}': {count}\")\n\n    except FileNotFoundError:\n        print(f\"Error: File '{file_path}' not found.\")", "test_code": "import string\nfrom collections import Counter\n\n\nclass Testword_count:\n    def test_word_count_case_sensitive_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_case_sensitive.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"Case case CASE\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'case': 3\" in captured.out\n\n\n    def test_word_count_punctuation_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_punctuation.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"This sentence has some punctuation, like commas and periods.\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'this': 1\\n'sentence': 1\\n'has': 1\\n'some': 1\\n'punctuation': 1\\n'like': 1\\n'commas': 1\\n'and': 1\\n'periods': 1\\n\" in captured.out\n\n\n    def test_word_count_same_word_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_same_word_multiple_times.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"word word word word word\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'word': 5\" in captured.out\n\n    def test_word_count_different_words_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_different_words_same_count.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"apple banana orange\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'apple': 1\\n'banana': 1\\n'orange': 1\\n\" in captured.out\n\n    def test_word_count_nonexistent_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'nonexistent_file.txt'\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"Error: File\" in captured.out\n\n    def test_word_count_empty_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_empty_file.txt'\n        open(file_path, 'w', encoding='utf-8').close()  # \u521b\u5efa\u4e00\u4e2a\u7a7a\u6587\u4ef6\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert captured.out.strip() == \"\"  # \u671f\u671b\u8f93\u51fa\u4e3a\u7a7a\u5b57\u7b26\u4e32\n\n", "required_packages": ["string", "collections"]}
{"id": "1", "title": "Word Frequency Counter", "description": "Given a file path, create a function `word_count` that reads the file, counts the occurrences of each word, and returns a dictionary containing the word counts.  The function should perform the following steps:", "language": "python", "difficulty": "medium", "category": "Algorithm and Data Structure", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nCreate a function named `word_count` that takes a file path as an argument, reads the file content, and counts the number of times each word appears in the file. The function should return a dictionary where the keys are the words and the values are the number of times that word appears in the file. It should ignore case and remove punctuation. Finally, the dictionary items should be sorted in descending order by the number of times the word appears. If multiple words appear the same number of times, they should be sorted in ascending alphabetical order. The function does not need to handle the case where the file does not exist.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testword_count:\n    def test_word_count_basic_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_basic.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"This is a basic test file with some common words.\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'this': 1\\n'is': 1\\n'a': 1\\n'basic': 1\\n'test': 1\\n'file': 1\\n'with': 1\\n'some': 1\\n'common': 1\\n'words': 1\\n\" in captured.out\n\n\n", "llm_code": "import string\n\ndef word_count(file_path):\n    \"\"\"\n    Counts the number of times each word appears in a file.\n\n    Args:\n        file_path (str): The path to the file.\n\n    Returns:\n        dict: A dictionary where the keys are the words and the values are the\n              number of times that word appears in the file. The dictionary is\n              sorted in descending order by the number of times the word\n              appears. If multiple words appear the same number of times, they\n              are sorted in ascending alphabetical order.\n    \"\"\"\n    word_counts = {}\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            line = line.strip().lower()\n            for char in string.punctuation:\n                line = line.replace(char, '')\n            words = line.split()\n            for word in words:\n                if word:\n                    word_counts[word] = word_counts.get(word, 0) + 1\n\n    sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: (-item[1], item[0])))\n\n    return sorted_word_counts", "correct_code": "import string\nfrom collections import Counter\n\n\ndef word_count(file_path):\n    try:\n        # \u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n\n        # \u79fb\u9664\u6807\u70b9\u7b26\u53f7\u5e76\u8f6c\u6362\u4e3a\u5c0f\u5199\n        translator = str.maketrans(\"\", \"\", string.punctuation)\n        content = content.translate(translator).lower()\n\n        # \u4f7f\u7528 Counter \u7edf\u8ba1\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\n        words = content.split()\n        word_counter = Counter(words)\n\n        # \u6309\u7167\u51fa\u73b0\u6b21\u6570\u964d\u5e8f\u6392\u5217\n        sorted_word_count = sorted(word_counter.items(), key=lambda x: x[1], reverse=True)\n\n        for word, count in sorted_word_count:\n            print(f\"'{word}': {count}\")\n\n    except FileNotFoundError:\n        print(f\"Error: File '{file_path}' not found.\")", "test_code": "import string\nfrom collections import Counter\n\n\nclass Testword_count:\n    def test_word_count_case_sensitive_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_case_sensitive.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"Case case CASE\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'case': 3\" in captured.out\n\n\n    def test_word_count_punctuation_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_punctuation.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"This sentence has some punctuation, like commas and periods.\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'this': 1\\n'sentence': 1\\n'has': 1\\n'some': 1\\n'punctuation': 1\\n'like': 1\\n'commas': 1\\n'and': 1\\n'periods': 1\\n\" in captured.out\n\n\n    def test_word_count_same_word_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_same_word_multiple_times.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"word word word word word\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'word': 5\" in captured.out\n\n    def test_word_count_different_words_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_different_words_same_count.txt'\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(\"apple banana orange\")\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"'apple': 1\\n'banana': 1\\n'orange': 1\\n\" in captured.out\n\n    def test_word_count_nonexistent_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'nonexistent_file.txt'\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert \"Error: File\" in captured.out\n\n    def test_word_count_empty_file(self, capfd, tmp_path):\n        file_path = tmp_path / 'test_empty_file.txt'\n        open(file_path, 'w', encoding='utf-8').close()  # \u521b\u5efa\u4e00\u4e2a\u7a7a\u6587\u4ef6\n        word_count(file_path)\n        captured = capfd.readouterr()\n        assert captured.out.strip() == \"\"  # \u671f\u671b\u8f93\u51fa\u4e3a\u7a7a\u5b57\u7b26\u4e32\n\n", "required_packages": ["string", "collections"]}
{"id": "10", "title": "Find Max Eigenvalues", "description": "Given a two-dimensional matrix (represented as a list of lists or a NumPy array) and an optional integer `num_largest` (defaulting to 5), your task is to find the `num_largest` maximum eigenvalues and their corresponding eigenvectors.  The matrix can be square or rectangular.", "language": "python", "difficulty": "medium", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a Python program named find_max_eigenvalues that calculates the maximum eigenvalues and corresponding eigenvectors of a two-dimensional matrix. The input parameters include a two-dimensional array matrix and an optional parameter `num_largest` (default value is 5), which is used to specify the number of maximum eigenvalues to be extracted. The program returns two lists, the first list is the eigenvalue list, and the second list is the corresponding eigenvector list. The program uses the NumPy and SciPy libraries for calculations. If the input matrix is empty or incorrectly formatted, the program will throw a ValueError. For example, for the input matrix: [[1, 2, 3], [4, 5, 6], [7, 8, 9]], and `num_largest` set to 2, the program should return the following results: Eigenvalue list: [18.8302358, -0.67276795], corresponding eigenvector list: [[-0.40962667, -0.54264865, -0.73330651], [0.43402538, -0.82296167, 0.36654613]]. Here, the first eigenvector [-0.40962667, -0.54264865, -0.73330651] corresponds to the maximum eigenvalue 18.8302358, and the second eigenvector [0.43402538, -0.82296167, 0.36654613] corresponds to the second largest eigenvalue -0.67276795.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcalculate_eigen:\n    def test_calculate_eigen_default(self):\n        test_matrix = np.array([[1, 2, 3, 4, 5],\n                                [6, 7, 8, 9, 10],\n                                [11, 12, 13, 14, 15],\n                                [16, 17, 18, 19, 20],\n                                [21, 22, 23, 24, 25]])\n\n        largest_eigenvalues, largest_eigenvectors = calculate_eigen(test_matrix)\n        assert len(largest_eigenvalues) == 5\n        assert largest_eigenvalues[0] < largest_eigenvalues[-1]\n\n", "llm_code": "import numpy as np\nfrom scipy.linalg import eigh\n\ndef find_max_eigenvalues(matrix, num_largest=5):\n    \"\"\"\n    Calculates the maximum eigenvalues and corresponding eigenvectors of a two-dimensional matrix.\n\n    Args:\n        matrix (numpy.ndarray): A two-dimensional array representing the matrix.\n        num_largest (int, optional): The number of maximum eigenvalues to be extracted. Defaults to 5.\n\n    Returns:\n        tuple: A tuple containing two lists:\n            - A list of the maximum eigenvalues.\n            - A list of the corresponding eigenvectors.\n\n    Raises:\n        ValueError: If the input matrix is empty or incorrectly formatted.\n    \"\"\"\n    if not isinstance(matrix, np.ndarray):\n        try:\n            matrix = np.array(matrix)\n        except:\n            raise ValueError(\"Input matrix could not be converted to a numpy array.\")\n\n    if matrix.size == 0:\n        raise ValueError(\"Input matrix cannot be empty.\")\n\n    if matrix.ndim != 2:\n        raise ValueError(\"Input matrix must be a two-dimensional array.\")\n\n    try:\n        eigenvalues, eigenvectors = eigh(matrix)\n    except np.linalg.LinAlgError:\n        raise ValueError(\"Failed to calculate eigenvalues. Ensure the matrix is square and contains numerical values.\")\n\n    eigenvalues = eigenvalues[-num_largest:]\n    eigenvectors = eigenvectors[:, -num_largest:]\n\n    return list(eigenvalues), eigenvectors.T.tolist()\n\ndef calculate_eigen(matrix, num_largest=5):\n    \"\"\"\n    Calculates the maximum eigenvalues and corresponding eigenvectors of a two-dimensional matrix.\n\n    Args:\n        matrix (numpy.ndarray): A two-dimensional array representing the matrix.\n        num_largest (int, optional): The number of maximum eigenvalues to be extracted. Defaults to 5.\n\n    Returns:\n        tuple: A tuple containing two lists:\n            - A list of the maximum eigenvalues.\n            - A list of the corresponding eigenvectors.\n\n    Raises:\n        ValueError: If the input matrix is empty or incorrectly formatted.\n    \"\"\"\n    if not isinstance(matrix, np.ndarray):\n        try:\n            matrix = np.array(matrix)\n        except:\n            raise ValueError(\"Input matrix could not be converted to a numpy array.\")\n\n    if matrix.size == 0:\n        raise ValueError(\"Input matrix cannot be empty.\")\n\n    if matrix.ndim != 2:\n        raise ValueError(\"Input matrix must be a two-dimensional array.\")\n\n    try:\n        eigenvalues, eigenvectors = eigh(matrix)\n    except np.linalg.LinAlgError:\n        raise ValueError(\"Failed to calculate eigenvalues. Ensure the matrix is square and contains numerical values.\")\n\n    eigenvalues = eigenvalues[-num_largest:]\n    eigenvectors = eigenvectors[:, -num_largest:]\n\n    return list(eigenvalues), eigenvectors.T.tolist()", "correct_code": "import numpy as np\nfrom scipy.linalg import eig\n\n\ndef calculate_eigen(matrix, num_largest=5):\n    # \u8ba1\u7b97\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf\n    eigenvalues, eigenvectors = eig(matrix)\n\n    # \u627e\u5230\u6700\u5927\u7684\u51e0\u4e2a\u7279\u5f81\u503c\u53ca\u5176\u5bf9\u5e94\u7684\u7d22\u5f15\n    largest_indices = np.argsort(eigenvalues)[-num_largest:]\n\n    # \u63d0\u53d6\u6700\u5927\u7684\u51e0\u4e2a\u7279\u5f81\u503c\u548c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\n    largest_eigenvalues = eigenvalues[largest_indices]\n    largest_eigenvectors = eigenvectors[:, largest_indices]\n\n    return largest_eigenvalues, largest_eigenvectors", "test_code": "import numpy as np\nfrom scipy.linalg import eig\n\n\nclass Testcalculate_eigen:\n    def test_calculate_eigen_custom(self):\n        test_matrix = np.array([[1, 2, 3, 4, 5],\n                                [6, 7, 8, 9, 10],\n                                [11, 12, 13, 14, 15],\n                                [16, 17, 18, 19, 20],\n                                [21, 22, 23, 24, 25]])\n\n        largest_eigenvalues, largest_eigenvectors = calculate_eigen(test_matrix, num_largest=3)\n        assert len(largest_eigenvalues) == 3\n        assert largest_eigenvalues[0] < largest_eigenvalues[-1]\n\n    def test_calculate_eigen_non_square_matrix(self):\n        non_square_matrix = np.array([[1, 2, 3], [4, 5, 6]])\n        with pytest.raises(ValueError):\n            calculate_eigen(non_square_matrix)\n\n    def test_calculate_eigen_empty_matrix(self):\n        empty_matrix = np.array([])\n        with pytest.raises(ValueError):\n            calculate_eigen(empty_matrix)\n\n    def test_calculate_eigen_large_matrix(self):\n        large_matrix = np.random.rand(100, 100)\n        largest_eigenvalues, _ = calculate_eigen(large_matrix, num_largest=10)\n        assert len(largest_eigenvalues) == 10\n        assert largest_eigenvalues[0] < largest_eigenvalues[-1]\n\n    def test_calculate_eigen_negative_values(self):\n        negative_matrix = np.array([[1, -2, 3], [-4, 5, -6], [7, -8, 9]])\n        largest_eigenvalues, _ = calculate_eigen(negative_matrix)\n        assert np.all(np.real(largest_eigenvalues) != 0)\n", "required_packages": ["numpy", "scipy"]}
{"id": "11", "title": "Flatten a Nested List", "description": "Given a nested list of integers, your task is to flatten it into a single, one-dimensional list.  A nested list is a list that may contain other lists as elements, which in turn can contain more lists, and so on.  The flattening process should extract all the integer elements from these nested lists and arrange them into a single, flat list.", "language": "python", "difficulty": "medium", "category": "Algorithm and Data Structure", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a Python program to flatten a nested list into a one-dimensional list. Define a function called flatten_list to flatten the nested list into a one-dimensional list, and the return value is the flattened_list after flattening. \nCreate an empty list flattened_list to store the elements after flattening. \nCreate a stack stack, and push the initial nested list nested_list into the stack. \nUse a loop to iterate until the stack is empty. \nIn each iteration, pop the current list current from the stack. \nFor each element in current, check its type: \nIf it is a list, push the list into the stack for subsequent flattening. \nIf it is not a list, add the element to flattened_list. \nThe loop continues until the stack is empty, and finally get the flattened list. \nReturn the flattened list flattened_list. For example, \n# Define the nested list\nnested_list = [1, [2, 3, [4, 5]], 6, [7, [8, 9]]]\n\n# Use the flatten_list function to flatten the list\nflattened_list = flatten_list(nested_list)\n\n# Print the result after flattening\nprint(flattened_list)\nIn this example, nested_list contains nested sublists. By calling the flatten_list function, it is flattened into a one-dimensional list flattened_list.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testflatten_list:\n    def test_flatten_list_empty(self):\n        assert flatten_list([]) == []\n\n", "llm_code": "def flatten_list(nested_list):\n    flattened_list = []\n    stack = [nested_list]\n    while stack:\n        current = stack.pop()\n        for element in reversed(current):\n            if isinstance(element, list):\n                stack.append(element)\n            else:\n                flattened_list.append(element)\n    return flattened_list[::-1]", "correct_code": "def flatten_list(nested_list):\n    flattened_list = []\n    stack = [nested_list]\n\n    while stack:\n        current = stack.pop()\n\n        for element in current:\n            if isinstance(element, list):\n                stack.append(element)\n            else:\n                flattened_list.append(element)\n\n    return flattened_list", "test_code": "\n\nclass Testflatten_list:\n    def test_flatten_list_single_level(self):\n        input_nested_list = [1, 2, 3, 4]\n        assert flatten_list(input_nested_list) == [1, 2, 3, 4]\n\n    def test_flatten_list_nested(self):\n        input_nested_list = [[1, 2, [3, 4]], [5, [6, 7]]]\n        assert flatten_list(input_nested_list) == [5, 6, 7, 1, 2, 3, 4]\n\n    def test_flatten_list_nested_empty(self):\n        input_nested_list = [[], [1, [2, 3], []], []]\n        assert flatten_list(input_nested_list) == [1, 2, 3]\n\n    def test_flatten_list_nested_strings(self):\n        input_nested_list = [['a', 'b', ['c', 'd']], ['e', ['f', 'g']]]\n        assert flatten_list(input_nested_list) == ['e', 'f', 'g', 'a', 'b', 'c', 'd']\n\n    def test_flatten_list_mixed_types(self):\n        input_nested_list = [1, 'a', [2, 'b', [3, 'c']], [4, 'd']]\n        assert flatten_list(input_nested_list) == [1, 'a', 4, 'd', 2, 'b', 3, 'c']\n\n    def test_flatten_list_nested_floats(self):\n        input_nested_list = [1.0, [2.5, [3.2, 4.8]], 5.6, [7.3, [8.1, 9.0]]]\n        assert flatten_list(input_nested_list) == [1.0, 5.6, 7.3, 8.1, 9.0, 2.5, 3.2, 4.8]\n\n    def test_flatten_list_nested_booleans(self):\n        input_nested_list = [True, [False, [True, False]], True, [False, True]]\n        assert flatten_list(input_nested_list) == [True, True, False, True, False, True, False]\n", "required_packages": []}
{"id": "12", "title": "VOC Label Conversion with IoU Threshold", "description": "Given a set of bounding boxes in VOC XML format and a target bounding box, you need to modify the labels of the objects.  Specifically, for each object in the XML file, calculate the Intersection over Union (IoU) between its bounding box and the target bounding box. If the IoU is greater than 0.2, change the object's label (the `<name>` tag's text content) to \"0\". The bounding box coordinates are represented as tuples `(xmin, ymin, xmax, ymax)`.  The provided code utilizes the `xml.etree.ElementTree` library to parse and modify the XML structure.  The `calculate_iou` function computes the IoU of two bounding boxes. The `convert_labels` function processes the VOC XML file, updating object labels based on the IoU with the target box.", "language": "python", "difficulty": "medium", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nUse Python, the label data is in VOC format, implement the division of the real box labels with an IoU greater than 0.2 in the given area into category 0.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testconvert_labels:\n    def test_convert_labels_1(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>950</xmin><ymin>786</ymin><xmax>1400</xmax><ymax>1052</ymax></bndbox><name>1</name></object></annotation>')\n        convert_labels(str(p), (950,786,1400,1052))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '0'\n\n", "llm_code": "import xml.etree.ElementTree as ET\n\ndef calculate_iou(box1, box2):\n    \"\"\"\n    Calculate the Intersection over Union (IoU) of two bounding boxes.\n\n    Args:\n        box1 (tuple): (xmin, ymin, xmax, ymax) of the first bounding box.\n        box2 (tuple): (xmin, ymin, xmax, ymax) of the second bounding box.\n\n    Returns:\n        float: IoU value.\n    \"\"\"\n    xmin1, ymin1, xmax1, ymax1 = box1\n    xmin2, ymin2, xmax2, ymax2 = box2\n\n    # Calculate the coordinates of the intersection rectangle\n    x_left = max(xmin1, xmin2)\n    y_top = max(ymin1, ymin2)\n    x_right = min(xmax1, xmax2)\n    y_bottom = min(ymax1, ymax2)\n\n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n\n    # Calculate the area of intersection rectangle\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n\n    # Calculate the area of both bounding boxes\n    box1_area = (xmax1 - xmin1) * (ymax1 - ymin1)\n    box2_area = (xmax2 - xmin2) * (ymax2 - ymin2)\n\n    # Calculate the IoU\n    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n    return iou\n\n\ndef convert_labels(xml_file, target_box):\n    \"\"\"\n    Convert object names to '0' if their IoU with the target box is greater than 0.2.\n\n    Args:\n        xml_file (str): Path to the XML file in VOC format.\n        target_box (tuple): (xmin, ymin, xmax, ymax) of the target bounding box.\n    \"\"\"\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n\n    for obj in root.findall('object'):\n        bbox = obj.find('bndbox')\n        xmin = int(bbox.find('xmin').text)\n        ymin = int(bbox.find('ymin').text)\n        xmax = int(bbox.find('xmax').text)\n        ymax = int(bbox.find('ymax').text)\n\n        object_box = (xmin, ymin, xmax, ymax)\n        iou = calculate_iou(object_box, target_box)\n\n        if iou > 0.2:\n            obj.find('name').text = '0'\n\n    tree.write(xml_file)", "correct_code": "import xml.etree.ElementTree as ET\n \ndef calculate_iou(box1, box2):\n    \"\"\"\n    \u8ba1\u7b97\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684IoU\n    \"\"\"\n    x1, y1, x2, y2 = box1\n    x3, y3, x4, y4 = box2\n\n    # \u8ba1\u7b97\u76f8\u4ea4\u77e9\u5f62\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u5750\u6807\n    inter_x1 = max(x1, x3)\n    inter_y1 = max(y1, y3)\n    inter_x2 = min(x2, x4)\n    inter_y2 = min(y2, y4)\n\n    # \u8ba1\u7b97\u76f8\u4ea4\u77e9\u5f62\u7684\u9762\u79ef\n    inter_area = max(0, inter_x2 - inter_x1 + 1) * max(0, inter_y2 - inter_y1 + 1)\n\n    # \u8ba1\u7b97\u5e76\u96c6\u9762\u79ef\u548cIoU\n    box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n    box2_area = (x4 - x3 + 1) * (y4 - y3 + 1)\n    union_area = box1_area + box2_area - inter_area\n    iou = inter_area / union_area\n\n    return iou\n\ndef convert_labels(label_file, target_region):\n    \"\"\"\n    \u5c06\u5728\u76ee\u6807\u533a\u57df\u5185\u4e0e\u771f\u5b9e\u6846\u6807\u7b7e\u7684IoU\u5927\u4e8e0.2\u7684\u6240\u6709\u6846\u6807\u7b7e\u5212\u5206\u4e3a\u7c7b\u522b0\n    \"\"\"\n    tree = ET.parse(label_file)\n    root = tree.getroot()\n\n    for object_elem in root.findall('object'):\n        bbox = object_elem.find('bndbox')\n        xmin = int(bbox.find('xmin').text)\n        ymin = int(bbox.find('ymin').text)\n        xmax = int(bbox.find('xmax').text)\n        ymax = int(bbox.find('ymax').text)\n\n        # \u8ba1\u7b97\u5f53\u524d\u8fb9\u754c\u6846\u4e0e\u76ee\u6807\u533a\u57df\u7684IoU\n        iou = calculate_iou(target_region, (xmin, ymin, xmax, ymax))\n\n        # \u5982\u679cIoU\u5927\u4e8e0.2\uff0c\u5219\u5c06\u7c7b\u522b\u8bbe\u7f6e\u4e3a0\n        if iou > 0.2:\n            object_elem.find('name').text = '0'\n\n    tree.write(label_file)", "test_code": "import xml.etree.ElementTree as ET\n\n\nclass Testconvert_labels:\n    def test_convert_labels_2(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>0</xmin><ymin>0</ymin><xmax>2</xmax><ymax>2</ymax></bndbox><name>1</name></object></annotation>')\n        convert_labels(str(p), (1,1,3,3))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '0'\n\n    def test_convert_labels_3(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>0</xmin><ymin>0</ymin><xmax>2</xmax><ymax>2</ymax></bndbox><name>1</name></object></annotation>')\n        convert_labels(str(p), (2,2,4,4))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '1'\n\n    def test_convert_labels_4(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>0</xmin><ymin>0</ymin><xmax>2</xmax><ymax>2</ymax></bndbox><name>1</name></object></annotation>')\n        convert_labels(str(p), (0,0,2,2))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '0'\n\n    def test_convert_labels_5(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>1000</xmin><ymin>800</ymin><xmax>1300</xmax><ymax>1000</ymax></bndbox><name>1</name></object></annotation>')\n        convert_labels(str(p), (950,786,1400,1052))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '0'\n\n    def test_convert_labels_6(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>900</xmin><ymin>750</ymin><xmax>1450</xmax><ymax>1100</ymax></bndbox><name>1</name></object></annotation>')\n        convert_labels(str(p), (950,786,1400,1052))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '0'\n\n    def test_convert_labels_7(self, tmp_path):\n        d = tmp_path / \"sub\"\n        d.mkdir()\n        p = d / \"label.xml\"\n        p.write_text('<annotation><object><bndbox><xmin>950</xmin><ymin>786</ymin><xmax>1400</xmax><ymax>1052</ymax></bndbox><name>2</name></object></annotation>')\n        convert_labels(str(p), (950,786,1400,1052))\n        tree = ET.parse(str(p))\n        root = tree.getroot()\n        assert root.find('object').find('name').text == '0'", "required_packages": ["xml"]}
{"id": "13", "title": "Dataset Splitter", "description": "You are given a path to a dataset directory `dataset_path` containing image files. Your task is to split this dataset into three subsets: training, test, and validation sets.  You will be provided with the desired ratios for each set (`train_ratio`, `test_ratio`, `val_ratio`). These ratios are floating-point numbers between 0 and 1, and they must sum up to 1.0.  A `random_seed` is also provided (defaulting to 42) to ensure reproducibility.", "language": "python", "difficulty": "easy", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nDivide the image classification dataset into training set, test set, and validation set, with the random seed set at 42.\nThe input is the path of the image folder, and the ratio of dividing the training set, test set, and validation set.\nThe output is the folder of the training set, test set, and validation set, and the output folder is directly placed in the dataset directory.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testsplit_data:\n    def test_split_data_1(self):\n        dataset_path = 'test1'\n        file_num = len(os.listdir(dataset_path))\n        train_ratio = 0.7\n        test_ratio = 0.2\n        val_ratio = 0.1\n        split_data(dataset_path,train_ratio,test_ratio,val_ratio)\n        assert len(os.listdir(os.path.join(dataset_path,'train'))) == file_num * train_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'test'))) == file_num * test_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'val'))) == file_num * val_ratio\n\n", "llm_code": "import os\nimport random\nimport shutil\n\ndef split_data(dataset_path, train_ratio, test_ratio, val_ratio, random_seed=42):\n    \"\"\"\n    Divides an image classification dataset into training, test, and validation sets.\n\n    Args:\n        dataset_path (str): Path to the image folder.\n        train_ratio (float): Ratio of images for the training set.\n        test_ratio (float): Ratio of images for the test set.\n        val_ratio (float): Ratio of images for the validation set.\n        random_seed (int): Random seed for shuffling and splitting.\n    \"\"\"\n\n    if not os.path.exists(dataset_path):\n        raise ValueError(f\"Dataset path '{dataset_path}' does not exist.\")\n\n    if not (train_ratio + test_ratio + val_ratio == 1.0):\n        raise ValueError(\"Train, test, and validation ratios must sum to 1.0.\")\n\n    random.seed(random_seed)\n\n    # Create output directories\n    train_dir = os.path.join(dataset_path, 'train')\n    test_dir = os.path.join(dataset_path, 'test')\n    val_dir = os.path.join(dataset_path, 'val')\n\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)\n    os.makedirs(val_dir, exist_ok=True)\n\n    # Get list of all files in the dataset directory\n    all_files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n\n    # Shuffle the files randomly\n    random.shuffle(all_files)\n\n    # Calculate the number of files for each set\n    num_files = len(all_files)\n    num_train = int(num_files * train_ratio)\n    num_test = int(num_files * test_ratio)\n    num_val = num_files - num_train - num_test\n\n    # Split the files into training, test, and validation sets\n    train_files = all_files[:num_train]\n    test_files = all_files[num_train:num_train + num_test]\n    val_files = all_files[num_train + num_test:]\n\n    # Move the files to their respective directories\n    for file in train_files:\n        src_path = os.path.join(dataset_path, file)\n        dst_path = os.path.join(train_dir, file)\n        shutil.move(src_path, dst_path)\n\n    for file in test_files:\n        src_path = os.path.join(dataset_path, file)\n        dst_path = os.path.join(test_dir, file)\n        shutil.move(src_path, dst_path)\n\n    for file in val_files:\n        src_path = os.path.join(dataset_path, file)\n        dst_path = os.path.join(val_dir, file)\n        shutil.move(src_path, dst_path)", "correct_code": "import os\nimport random\nimport shutil\n\n\ndef split_data(dataset_path,train_ratio,test_ratio,val_ratio):\n    # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\n    random_seed = 42\n    random.seed(random_seed)\n    train_path = os.path.join(dataset_path,'train')\n    test_path = os.path.join(dataset_path,'test')\n    val_path = os.path.join(dataset_path,'val')\n\n    if not os.path.exists(train_path):\n        os.makedirs(train_path)\n\n    if not os.path.exists(test_path):\n        os.makedirs(test_path)\n\n    if not os.path.exists(val_path):\n        os.makedirs(val_path)\n\n    image_files = [f for f in os.listdir(dataset_path) if f.endswith('.jpg')]\n\n    # \u968f\u673a\u6253\u4e71\u56fe\u50cf\u6587\u4ef6\u5217\u8868\n    random.shuffle(image_files)\n\n    # \u8ba1\u7b97\u5212\u5206\u7684\u7d22\u5f15\u4f4d\u7f6e\n    train_split = int(len(image_files) * train_ratio)\n    test_split = int(len(image_files) * (train_ratio + test_ratio))\n\n    # \u5212\u5206\u8bad\u7ec3\u96c6\n    train_files = image_files[:train_split]\n    for file in train_files:\n        src_path = os.path.join(dataset_path, file)\n        dest_path = os.path.join(train_path, file)\n        shutil.copy(src_path, dest_path)\n\n    # \u5212\u5206\u6d4b\u8bd5\u96c6\n    test_files = image_files[train_split:test_split]\n    for file in test_files:\n        src_path = os.path.join(dataset_path, file)\n        dest_path = os.path.join(test_path, file)\n        shutil.copy(src_path, dest_path)\n\n    # \u5212\u5206\u9a8c\u8bc1\u96c6\n    val_files = image_files[test_split:]\n    for file in val_files:\n        src_path = os.path.join(dataset_path, file)\n        dest_path = os.path.join(val_path, file)\n        shutil.copy(src_path, dest_path)\n\n\n# import os\n# import shutil\n# from sklearn.model_selection import train_test_split\n\n\n# def split_data(dataset_path, train_ratio, test_ratio, val_ratio):\n#     # \u83b7\u53d6\u6240\u6709\u6587\u4ef6\u7684\u8def\u5f84\n#     files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if\n#              os.path.isfile(os.path.join(dataset_path, f))]\n#\n#     # \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u5176\u4f59\u90e8\u5206\n#     train_files, rest_files = train_test_split(files, train_size=train_ratio, random_state=42)\n#\n#     # \u8ba1\u7b97\u6d4b\u8bd5\u96c6\u7684\u6bd4\u4f8b\n#     test_ratio_adjusted = test_ratio / (1 - train_ratio)\n#\n#     # \u5212\u5206\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6\n#     test_files, val_files = train_test_split(rest_files, test_size=test_ratio_adjusted, random_state=42)\n#\n#     # \u521b\u5efa\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u6587\u4ef6\u5939\n#     train_dir = os.path.join(dataset_path, 'train')\n#     test_dir = os.path.join(dataset_path, 'test')\n#     val_dir = os.path.join(dataset_path, 'val')\n#     os.makedirs(train_dir, exist_ok=True)\n#     os.makedirs(test_dir, exist_ok=True)\n#     os.makedirs(val_dir, exist_ok=True)\n#\n#     # \u5c06\u6587\u4ef6\u79fb\u52a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5939\n#     for f in train_files:\n#         shutil.move(f, os.path.join(train_dir, os.path.basename(f)))\n#     for f in test_files:\n#         shutil.move(f, os.path.join(test_dir, os.path.basename(f)))\n#     for f in val_files:\n#         shutil.move(f, os.path.join(val_dir, os.path.basename(f)))", "test_code": "import os\nimport random\nimport shutil\n\nclass Testsplit_data:\n    def test_split_data_2(self):\n        dataset_path = 'test2'\n        file_num = len(os.listdir(dataset_path))\n        train_ratio = 1\n        test_ratio = 0\n        val_ratio = 0\n        split_data(dataset_path,train_ratio,test_ratio,val_ratio)\n        assert len(os.listdir(os.path.join(dataset_path, 'train'))) == file_num * train_ratio\n        assert len(os.listdir(os.path.join(dataset_path, 'test'))) == file_num * test_ratio\n        assert len(os.listdir(os.path.join(dataset_path, 'val'))) == file_num * val_ratio\n\n    def test_split_data_3(self):\n        dataset_path = 'test3'\n        file_num = len(os.listdir(dataset_path))\n        train_ratio = 0\n        test_ratio = 1\n        val_ratio = 0\n        split_data(dataset_path,train_ratio,test_ratio,val_ratio)\n        assert len(os.listdir(os.path.join(dataset_path,'train'))) == file_num * train_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'test'))) == file_num * test_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'val'))) == file_num * val_ratio\n\n    def test_split_data_4(self):\n        dataset_path = 'test4'\n        file_num = len(os.listdir(dataset_path))\n        train_ratio = 0\n        test_ratio = 0\n        val_ratio = 1\n        split_data(dataset_path,train_ratio,test_ratio,val_ratio)\n        assert len(os.listdir(os.path.join(dataset_path,'train'))) == file_num * train_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'test'))) == file_num * test_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'val'))) == file_num * val_ratio\n\n    def test_split_data_5(self):\n        dataset_path = 'test5'\n        file_num = len(os.listdir(dataset_path))\n        train_ratio = 0.6\n        test_ratio = 0.3\n        val_ratio = 0.1\n        split_data(dataset_path,train_ratio,test_ratio,val_ratio)\n        assert len(os.listdir(os.path.join(dataset_path,'train'))) == file_num * train_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'test'))) == file_num * test_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'val'))) == file_num * val_ratio\n\n    def test_split_data_6(self):\n        dataset_path = 'test6'\n        file_num = len(os.listdir(dataset_path))\n        train_ratio = 0.6\n        test_ratio = 0.2\n        val_ratio = 0.2\n        split_data(dataset_path,train_ratio,test_ratio,val_ratio)\n        assert len(os.listdir(os.path.join(dataset_path,'train'))) == file_num * train_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'test'))) == file_num * test_ratio\n        assert len(os.listdir(os.path.join(dataset_path,'val'))) == file_num * val_ratio\n", "required_packages": ["os", "shutil", "random"]}
{"id": "14", "title": "YOLO Annotation Category Filter", "description": "You are given a folder path containing YOLO format annotation files (`.txt`). Each line in an annotation file represents an object with its category ID as the first space-separated value (e.g., `0 0.5 0.5 0.2 0.2`). You are also given a list of allowed category IDs, `Label_category`.  Your task is to modify the annotation files in-place, removing lines corresponding to objects with category IDs *not* present in `Label_category`.", "language": "python", "difficulty": "easy", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nFilter the category in the annotation files of the yolo format dataset in the field of image processing, only retain the category labels in Label_category, and delete other category labels, operate on the original file. Enter the path of the annotation file folder of the yolo format dataset and the Label_category list.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testlabel_filter:\n    def test_label_filter_1(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test1.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [1,2,3])\n        assert p.read() == \"0 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\\n\"\n\n", "llm_code": "import os\n\ndef label_filter(folder_path, Label_category):\n    \"\"\"\n    Filter the category in the annotation files of the yolo format dataset,\n    only retain the category labels in Label_category, and delete other category labels,\n    operate on the original file.\n    Args:\n        folder_path: the path of the annotation file folder of the yolo format dataset\n        Label_category: the Label_category list\n    \"\"\"\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".txt\"):\n            file_path = os.path.join(folder_path, filename)\n            with open(file_path, \"r\") as f:\n                lines = f.readlines()\n\n            filtered_lines = []\n            deleted_lines = []\n            for line in lines:\n                category = int(line.split()[0])\n                if category in Label_category:\n                    deleted_lines.append(line)\n                else:\n                    filtered_lines.append(line)\n            \n            with open(file_path, \"w\") as f:\n                for line in filtered_lines:\n                    f.write(line)", "correct_code": "import os\n\n\ndef label_filter(folder_path,Label_category):\n\n    txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n    for file_name in txt_files:\n        file_path = os.path.join(folder_path, file_name)\n        with open(file_path, 'r') as file:\n            lines = file.readlines()\n\n        new_lines = []\n\n\n        for line in lines:\n            parts = line.split()\n\n            if int(parts[0]) in Label_category :\n                continue\n            new_line = ' '.join(parts) + '\\n'\n            new_lines.append(new_line)\n\n        # \u5c06\u5904\u7406\u540e\u7684\u884c\u5199\u56de\u6587\u4ef6\n        with open(file_path, 'w') as file:\n            file.writelines(new_lines)", "test_code": "import os\n\n\nclass Testlabel_filter:\n    def test_label_filter_2(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test2.txt\")\n        p.write(\"1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [1,2,3])\n        assert p.read() == \"\"\n\n    def test_label_filter_3(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test3.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [1,2,3])\n        assert p.read() == \"0 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\\n\"\n\n    def test_label_filter_4(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test4.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [0,4])\n        assert p.read() == \"1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n\"\n\n    def test_label_filter_5(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test5.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [])\n        assert p.read() == \"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\\n\"\n\n    def test_label_filter_6(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test6.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\\n\")\n        label_filter(str(tmpdir / \"sub\"), [0,1,2,3,4])\n        assert p.read() == \"\"\n\n    def test_label_filter_7(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test7.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [5,6,7])\n        assert p.read() == \"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\\n\"\n\n    def test_label_filter_8(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test8.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [0])\n        assert p.read() == \"1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\\n\"\n\n    def test_label_filter_9(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test9.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [4])\n        assert p.read() == \"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n\"\n\n    def test_label_filter_10(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test10.txt\")\n        p.write(\"0 0.5 0.5 0.5 0.5\\n1 0.5 0.5 0.5 0.5\\n2 0.5 0.5 0.5 0.5\\n3 0.5 0.5 0.5 0.5\\n4 0.5 0.5 0.5 0.5\")\n        label_filter(str(tmpdir / \"sub\"), [0,1,2,3])\n        assert p.read() == \"4 0.5 0.5 0.5 0.5\\n\"", "required_packages": ["os"]}
{"id": "15", "title": "YOLO Annotation Size Filter", "description": "You are given a folder `annotation_folder` containing YOLO format annotation files (`.txt`). Each line in these files represents a bounding box and follows the format: `<class_id> <center_x> <center_y> <width> <height>`.", "language": "python", "difficulty": "easy", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nPerform category filtering on the annotation files of the yolo format dataset in the field of image processing, where both w and h are greater than limit_wideth and limit_height, operate on the original file. Input the annotation folder path of the yolo format dataset and limit_wideth, limit_height.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testw_h_filter:\n    def test_w_h_filter_1(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.15, 0.15)\n        assert p.read() == \"1 0.5 0.5 0.2 0.2\\n\"\n\n", "llm_code": "import os\n\ndef w_h_filter(annotation_folder, limit_wideth, limit_height):\n    \"\"\"\n    Filters YOLO format annotation files, removing lines where width and height are below the specified limits.\n    Operates directly on the original files.\n\n    Args:\n        annotation_folder (str): Path to the folder containing YOLO annotation files.\n        limit_wideth (float): Minimum allowed width.\n        limit_height (float): Minimum allowed height.\n    \"\"\"\n    for filename in os.listdir(annotation_folder):\n        if filename.endswith(\".txt\"):\n            filepath = os.path.join(annotation_folder, filename)\n            with open(filepath, \"r\") as f:\n                lines = f.readlines()\n\n            filtered_lines = []\n            for line in lines:\n                parts = line.strip().split()\n                if len(parts) == 5:\n                    try:\n                        width = float(parts[3])\n                        height = float(parts[4])\n                        if width > limit_wideth and height > limit_height:\n                            filtered_lines.append(line)\n                    except ValueError:\n                        # Handle cases where conversion to float fails (e.g., corrupted data)\n                        print(f\"Skipping line due to ValueError: {line.strip()} in file: {filename}\")\n                        continue  # Skip the problematic line\n\n                else:\n                    print(f\"Skipping line due to incorrect number of fields: {line.strip()} in file: {filename}\")\n                    continue # skip the problematic line\n\n            with open(filepath, \"w\") as f:\n                f.writelines(filtered_lines)", "correct_code": "import os\n\n\ndef w_h_filter(folder_path,limit_wideth,limit_height):\n    txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n    for file_name in txt_files:\n        file_path = os.path.join(folder_path, file_name)\n        with open(file_path, 'r') as file:\n            lines = file.readlines()\n\n        new_lines = []\n\n\n        for line in lines:\n            parts = line.split()\n\n            if (float(parts[3]) < limit_wideth or float(parts[4]) < limit_height):\n                continue\n            new_line = ' '.join(parts) + '\\n'\n            new_lines.append(new_line)\n\n        # \u5c06\u5904\u7406\u540e\u7684\u884c\u5199\u56de\u6587\u4ef6\n        with open(file_path, 'w') as file:\n            file.writelines(new_lines)\n\n\n\n\n# if __name__ == \"__main__\":\n#\n#     folder_path = r\"C:\\Users\\Administrator\\Desktop\\work\\1207-Q14\\labels\"\n#     limit_wideth=0.1\n#     limit_height=0.02\n#     w_h_filter(folder_path,limit_wideth,limit_height)", "test_code": "import os\n\n\nclass Testw_h_filter:\n    def test_w_h_filter_2(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.05, 0.05)\n        assert p.read() == \"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_3(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.2, 0.2)\n        assert p.read() == \"1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_4(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.1, 0.1)\n        assert p.read() == \"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_5(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.1, 0.2)\n        assert p.read() == \"1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_6(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.2, 0.1)\n        assert p.read() == \"1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_7(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0, 0)\n        assert p.read() == \"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_8(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 1, 1)\n        assert p.read() == \"\"\n\n    def test_w_h_filter_9(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.2, 0.2)\n        assert p.read() == \"1 0.5 0.5 0.2 0.2\\n\"\n\n    def test_w_h_filter_10(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"test.txt\")\n        p.write(\"0 0.5 0.5 0.1 0.1\\n1 0.5 0.5 0.2 0.2\")\n        w_h_filter(str(tmpdir / \"sub\"), 0.15, 0.15)\n        assert p.read() == \"1 0.5 0.5 0.2 0.2\\n\"", "required_packages": ["os"]}
{"id": "16", "title": "Sentence Processing with NLTK", "description": "Given a sentence string, perform basic Natural Language Processing (NLP) preprocessing steps using the NLTK library.", "language": "python", "difficulty": "easy", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nImport the nltk package. Define a function with a parameter to receive a sentence, perform tokenization, part-of-speech tagging, stop word removal, and stem extraction operations on this sentence, and output the results of each operation. Then call the defined function.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testprocess_sentence:\n    def test_process_sentence_1(self):\n        assert process_sentence(\"Hello, world!\") == (['Hello', ',', 'world', '!'], [('Hello', 'NNP'), (',', ','), ('world', 'NN'), ('!', '.')], ['hello', ',', 'world', '!'], ['hello', ',', 'world', '!'])\n\n", "llm_code": "import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\ndef process_sentence(sentence):\n    \"\"\"\n    Performs tokenization, part-of-speech tagging, stop word removal,\n    and stem extraction on a sentence.\n\n    Args:\n        sentence (str): The sentence to process.\n\n    Returns:\n        tuple: A tuple containing the results of each operation:\n            - tokenized_words (list): List of tokens.\n            - pos_tagged_words (list): List of (token, POS tag) tuples.\n            - stop_words_removed (list): List of tokens after stop word removal.\n            - stemmed_words (list): List of stemmed tokens.\n    \"\"\"\n\n    # Tokenization\n    tokenized_words = word_tokenize(sentence)\n\n    # Part-of-speech tagging\n    pos_tagged_words = nltk.pos_tag(tokenized_words)\n\n    # Stop word removal\n    stop_words = set(stopwords.words('english'))\n    stop_words_removed = [w.lower() for w in tokenized_words if w.lower() not in stop_words]\n\n    # Stem extraction\n    stemmer = PorterStemmer()\n    stemmed_words = [stemmer.stem(w.lower()) for w in tokenized_words]\n\n    return tokenized_words, pos_tagged_words, [w.lower() for w in tokenized_words], stemmed_words", "correct_code": "import nltk\nnltk.data.path.append('nltk_package')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk import pos_tag\n\n\ndef process_sentence(sentence):\n    tokens = word_tokenize(sentence)\n    pos_tags = pos_tag(tokens)\n    # stop_words = set(stopwords.words('english'))\n    # filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n    filtered_tokens = [word.lower() for word in tokens]\n    stemmer = PorterStemmer()\n    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n    # \u8f93\u51fa\u7ed3\u679c\n    print(\"Original Sentence:\\n\", sentence)\n    print(\"\\nTokenized Sentence:\\n\", tokens)\n    print(\"\\nPOS Tagged Sentence:\\n\", pos_tags)\n    print(\"\\nSentence without Stopwords:\\n\", filtered_tokens)\n    print(\"\\nStemmed Sentence:\\n\", stemmed_tokens)\n    return tokens, pos_tags, filtered_tokens, stemmed_tokens\n\nprint(process_sentence(\"!@#$%^&*()\"))", "test_code": "import nltk\nnltk.data.path.append('averaged_perceptron_tagger')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\n\n\nclass Testprocess_sentence:\n    def test_process_sentence_2(self):\n        assert process_sentence(\"I am a student.\") == (['I', 'am', 'a', 'student', '.'], [('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('student', 'NN'), ('.', '.')], ['i', 'am', 'a', 'student', '.'], ['i', 'am', 'a', 'student', '.'])\n\n    def test_process_sentence_3(self):\n        assert process_sentence(\"This is a test sentence.\") == (['This', 'is', 'a', 'test', 'sentence', '.'], [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('test', 'NN'), ('sentence', 'NN'), ('.', '.')], ['this', 'is', 'a', 'test', 'sentence', '.'], ['thi', 'is', 'a', 'test', 'sentenc', '.'])\n\n    def test_process_sentence_4(self):\n        assert process_sentence(\"The quick brown fox jumps over the lazy dog.\") == (['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'], ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog', '.'])\n\n    def test_process_sentence_5(self):\n        assert process_sentence(\"Python is a high-level programming language.\") == (['Python', 'is', 'a', 'high-level', 'programming', 'language', '.'], [('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), ('programming', 'NN'), ('language', 'NN'), ('.', '.')], ['python', 'is', 'a', 'high-level', 'programming', 'language', '.'], ['python', 'is', 'a', 'high-level', 'program', 'languag', '.'])\n\n    def test_process_sentence_6(self):\n        assert process_sentence(\"It's a beautiful day!\") == (['It', \"'s\", 'a', 'beautiful', 'day', '!'], [('It', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('day', 'NN'), ('!', '.')], ['it', \"'s\", 'a', 'beautiful', 'day', '!'], ['it', \"'s\", 'a', 'beauti', 'day', '!'])\n\n    def test_process_sentence_7(self):\n        assert process_sentence(\"\") == ([], [], [], [])\n\n    def test_process_sentence_8(self):\n        assert process_sentence(\" \") == ([], [], [], [])\n\n    def test_process_sentence_9(self):\n        assert process_sentence(\"123\") == (['123'], [('123', 'CD')], ['123'], ['123'])\n\n    def test_process_sentence_10(self):\n        assert process_sentence(\"!@#$%^&*()\") == (['!', '@', '#', '$', '%', '^', '&', '*', '(', ')'], [('!', '.'), ('@', 'JJ'), ('#', '#'), ('$', '$'), ('%', 'NN'), ('^', 'NNP'), ('&', 'CC'), ('*', 'NNP'), ('(', '('), (')', ')')], ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')'], ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')'])", "required_packages": ["nltk"]}
{"id": "17", "title": "Survival Probability and One-Hot Encoding", "description": "You are given a CSV file named `dataset.csv` containing passenger data, including 'PassengerID', 'Survived', 'Pclass', 'Sex', and 'Age'.  Your task is twofold:", "language": "python", "difficulty": "easy", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nThere is a dataset.csv, which contains 5 columns: PassengerID, Survived, Pclass, Sex, Age. Please read the file and calculate the probability of the Sex column being female and the Survived column being 1, and the probability of the Sex column being male and the Survived column being 1. Finally, convert the non-numeric columns in the dataset to one-hot encoding, and save the dataset to a new file named new_train.csv.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcalculate_and_save_probabilities:\n    def test_case1(self):\n        assert calculate_and_save_probabilities(\"test1/dataset.csv\", \"test1/new_train.csv\") == (0.1, 0.8)\n        df1 = pd.read_csv(\"test1/new_train.csv\")\n        df2 = pd.read_csv(\"test1/test_label.csv\")\n        assert df1.equals(df2)\n\n", "llm_code": "import pandas as pd\n\ndef calculate_and_save_probabilities(input_csv, output_csv):\n    \"\"\"\n    Calculates the probability of survival given sex and saves the one-hot encoded DataFrame.\n\n    Args:\n        input_csv (str): Path to the input CSV file.\n        output_csv (str): Path to the output CSV file.\n\n    Returns:\n        tuple: (probability of female survival, probability of male survival)\n    \"\"\"\n    df = pd.read_csv(input_csv)\n\n    # Calculate probabilities\n    total_female = df['Sex'][df['Sex'] == 'female'].count()\n    female_survived = df['Survived'][(df['Sex'] == 'female') & (df['Survived'] == 1)].count()\n    prob_female_survival = female_survived / total_female if total_female > 0 else 0.0\n\n    total_male = df['Sex'][df['Sex'] == 'male'].count()\n    male_survived = df['Survived'][(df['Sex'] == 'male') & (df['Survived'] == 1)].count()\n    prob_male_survival = male_survived / total_male if total_male > 0 else 0.0\n\n    # Convert non-numeric columns to one-hot encoding\n    df = pd.get_dummies(df, columns=['Sex'])\n\n    # Save the DataFrame to a new CSV file\n    df.to_csv(output_csv, index=False)\n\n    return (prob_female_survival, prob_male_survival)", "correct_code": "import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n\n\ndef calculate_and_save_probabilities(input_file, output_file):\n    # \u8bfb\u53d6\u6570\u636e\u96c6\n    df = pd.read_csv(input_file)\n\n    # \u8ba1\u7b97\u6982\u7387\n    probabilities = {}\n    for column_value in df['Sex'].unique():\n        prob = df[(df['Sex'] == column_value) & (df[\"Survived\"] == 1)].shape[0] / df[df['Sex'] == column_value].shape[0]\n        probabilities[f\"Probability({'Sex'}={column_value}, {'Survived'}=1)\"] = prob\n\n    # \u6253\u5370\u8ba1\u7b97\u7ed3\u679c\n    for key, value in probabilities.items():\n        print(key + \":\", value)\n\n    # \u8fdb\u884c\u72ec\u70ed\u7f16\u7801\n    non_numeric_columns = df.select_dtypes(include=['object']).columns\n    encoder = OneHotEncoder(sparse=False)\n    encoded_features = pd.DataFrame(encoder.fit_transform(df[non_numeric_columns]))\n    encoded_features.columns = encoder.get_feature_names_out(non_numeric_columns)\n\n    # \u66ff\u6362\u539f\u59cb\u6570\u636e\u96c6\u4e2d\u7684\u975e\u6570\u503c\u5217\n    df.drop(non_numeric_columns, axis=1, inplace=True)\n    df = pd.concat([df, encoded_features], axis=1)\n\n    # \u5c06\u6570\u636e\u96c6\u4fdd\u5b58\u5230\u65b0\u6587\u4ef6\n    df.to_csv(output_file, index=False)\n\n    return probabilities[f\"Probability(Sex=male, Survived=1)\"], probabilities[\"Probability(Sex=female, Survived=1)\"]\n\n\nprint(calculate_and_save_probabilities(\"test6/dataset.csv\", \"test6/test_label.csv\"))", "test_code": "import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nclass Testcalculate_and_save_probabilities:\n    def test_case2(self):\n        assert calculate_and_save_probabilities(\"test2/dataset.csv\", \"test2/new_train.csv\") == (0.2, 0.8)\n        df1 = pd.read_csv(\"test2/new_train.csv\")\n        df2 = pd.read_csv(\"test2/test_label.csv\")\n        assert df1.equals(df2)\n\n    def test_case3(self):\n        assert calculate_and_save_probabilities(\"test3/dataset.csv\", \"test3/new_train.csv\") == (0.2727272727272727, 0.8888888888888888)\n        df1 = pd.read_csv(\"test3/new_train.csv\")\n        df2 = pd.read_csv(\"test3/test_label.csv\")\n        assert df1.equals(df2)\n\n    def test_case4(self):\n        assert calculate_and_save_probabilities(\"test4/dataset.csv\", \"test4/new_train.csv\") == (0.36363636363636365, 0.7777777777777778)\n        df1 = pd.read_csv(\"test4/new_train.csv\")\n        df2 = pd.read_csv(\"test4/test_label.csv\")\n        assert df1.equals(df2)\n\n    def test_case5(self):\n        assert calculate_and_save_probabilities(\"test5/dataset.csv\", \"test5/new_train.csv\") == (0.2, 0.8)\n        df1 = pd.read_csv(\"test5/new_train.csv\")\n        df2 = pd.read_csv(\"test5/test_label.csv\")\n        assert df1.equals(df2)\n\n    def test_case6(self):\n        assert calculate_and_save_probabilities(\"test6/dataset.csv\", \"test6/new_train.csv\") == (0.2222222222222222, 0.7272727272727273)\n        df1 = pd.read_csv(\"test6/new_train.csv\")\n        df2 = pd.read_csv(\"test6/test_label.csv\")\n        assert df1.equals(df2)", "required_packages": ["sklearn", "pandas"]}
{"id": "18", "title": "Linear Regression with NumPy", "description": "Given two vectors `x` and `y` of equal length, implement a function `linear_fit(x, y)` that uses the NumPy library to perform a linear regression (least squares fit).  The function should return the slope `a`, the y-intercept `b`, and the correlation coefficient `r`.  The vectors `x` and `y` represent the independent and dependent variables, respectively, for the linear relationship `y = ax + b`. You should use NumPy functions for efficiency and avoid explicit loops.  The correlation coefficient `r` measures the strength and direction of the linear relationship between the two variables.", "language": "python", "difficulty": "easy", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nGiven two vectors of equal length x, y, use the numpy toolkit to solve for a and b using the least squares method for linear fitting, and find the slope a, intercept b, and correlation coefficient r.\nFunction usage: a, b, r = linear_fit(x, y)\nPlease complete the code for the linear_fit function.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testlinear_fit:\n    def test_linear_fit_1(self):\n        x = [1, 2, 3, 4, 5]\n        y = [2, 4, 6, 8, 10]\n        a, b, r = linear_fit(x, y)\n        assert a == 2\n        assert b == 0\n        assert r == 0.9999999999999999\n\n", "llm_code": "import numpy as np\n\ndef linear_fit(x, y):\n    \"\"\"\n    Given two vectors of equal length x, y, use the numpy toolkit to solve for a and b using the least squares method for linear fitting, and find the slope a, intercept b, and correlation coefficient r.\n    Function usage: a, b, r = linear_fit(x, y)\n    \"\"\"\n    x = np.array(x)\n    y = np.array(y)\n    n = len(x)\n    \n    # Calculate the slope (a) and intercept (b)\n    a = (n * np.sum(x * y) - np.sum(x) * np.sum(y)) / (n * np.sum(x**2) - np.sum(x)**2)\n    b = (np.sum(y) - a * np.sum(x)) / n\n    \n    # Calculate the correlation coefficient (r)\n    y_predicted = a * x + b\n    \n    numerator = np.sum((y - np.mean(y)) * (y_predicted - np.mean(y_predicted)))\n    denominator_x = np.sqrt(np.sum((y - np.mean(y))**2))\n    denominator_y = np.sqrt(np.sum((y_predicted - np.mean(y_predicted))**2))\n    \n    r = numerator / (denominator_x * denominator_y)\n    \n    return a, b, r", "correct_code": "import numpy as np\n\n\ndef linear_fit(x, y):\n    x = np.array(x)\n    y = np.array(y)\n\n    mean_x = np.mean(x)\n    mean_y = np.mean(y)\n\n    SS_xy = np.dot(x - mean_x, y - mean_y)\n    SS_xx = np.dot(x - mean_x, x - mean_x)\n    a = SS_xy / SS_xx\n    b = mean_y - a * mean_x\n\n    r = np.corrcoef(x, y)[0, 1]\n\n    return a, b, r", "test_code": "import numpy as np\n\n\nclass Testlinear_fit:\n    def test_linear_fit_2(self):\n        x = [1, 2, 3, 4, 5]\n        y = [3, 5, 7, 9, 11]\n        a, b, r = linear_fit(x, y)\n        assert a == 2\n        assert b == 1\n        assert r == 0.9999999999999999\n\n    def test_linear_fit_3(self):\n        x = [1, 2, 3, 4, 5]\n        y = [1, 2, 3, 4, 5]\n        a, b, r = linear_fit(x, y)\n        assert a == 1\n        assert b == 0\n        assert r == 0.9999999999999999\n\n    def test_linear_fit_4(self):\n        x = [1, 2, 3, 4, 5]\n        y = [2, 3, 4, 5, 6]\n        a, b, r = linear_fit(x, y)\n        assert a == 1\n        assert b == 1\n        assert r == 0.9999999999999999\n\n    def test_linear_fit_5(self):\n        x = [1, 2, 3, 4, 5]\n        y = [5, 7, 9, 11, 13]\n        a, b, r = linear_fit(x, y)\n        assert a == 2\n        assert b == 3\n        assert r == 0.9999999999999999\n\n    def test_linear_fit_6(self):\n        x = [1, 2, 3, 4, 5]\n        y = [1, 1, 1, 1, 1]\n        a, b, r = linear_fit(x, y)\n        assert a == 0\n        assert b == 1\n        assert np.isnan(r)\n\n    def test_linear_fit_7(self):\n        x = [1, 1, 1, 1, 1]\n        y = [1, 2, 3, 4, 5]\n        a, b, r = linear_fit(x, y)\n        assert np.isnan(a)\n        assert np.isnan(b)\n        assert np.isnan(r)\n\n    def test_linear_fit_8(self):\n        x = [1, 2, 3, 4, 5]\n        y = [5, 4, 3, 2, 1]\n        a, b, r = linear_fit(x, y)\n        assert a == -1\n        assert b == 6\n        assert r == -0.9999999999999999\n\n    def test_linear_fit_9(self):\n        x = [1, 2, 3, 4, 5]\n        y = [10, 8, 6, 4, 2]\n        a, b, r = linear_fit(x, y)\n        assert a == -2\n        assert b == 12\n        assert r == -0.9999999999999999\n\n    def test_linear_fit_10(self):\n        x = [1, 2, 3, 4, 5]\n        y = [1, 4, 9, 16, 25]\n        a, b, r = linear_fit(x, y)\n        assert a == 6.0\n        assert b == -7.0\n        assert r == 0.981104910251593", "required_packages": ["numpy"]}
{"id": "19", "title": "CSV Column Average", "description": "", "language": "python", "difficulty": "easy", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nGiven a CSV file that contains multiple columns of data, each column consisting of numbers, read the file and calculate the average of the third column. (Hint, you need to skip the title row)\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcalculate_average:\n    def test_calculate_average_1(self):\n        assert calculate_average('test1.csv', 2) == 85\n\n", "llm_code": "import csv\n\ndef calculate_average(file_path, column_index):\n    \"\"\"\n    Calculates the average of a specified column in a CSV file.\n\n    Args:\n        file_path (str): The path to the CSV file.\n        column_index (int): The index of the column to average (0-based).\n\n    Returns:\n        float: The average of the specified column, or None if the file is empty or an error occurs.\n    \"\"\"\n    try:\n        with open(file_path, 'r') as csvfile:\n            reader = csv.reader(csvfile)\n            next(reader, None)  # Skip the header row.\n\n            column_values = []\n            for row in reader:\n                try:\n                    value = float(row[column_index])\n                    column_values.append(value)\n                except (ValueError, IndexError):\n                    # Handle cases where the value is not a number or the column doesn't exist in the row.\n                    pass  # or log the error\n\n            if column_values:\n                return sum(column_values) / len(column_values)\n            else:\n                return None  # Return None if the column is empty\n    except FileNotFoundError:\n        print(f\"Error: File not found at {file_path}\")\n        return None\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None", "correct_code": "import csv\n\ndef calculate_average(filename, column_index):\n    with open(filename, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)  \n        total, count = 0, 0\n        for row in reader:\n            if row[column_index].isdigit():\n                total += int(row[column_index])\n                count += 1\n        return total / count if count != 0 else 0", "test_code": "\n\nclass Testcalculate_average:\n    def test_calculate_average_2(self):\n        assert calculate_average('test2.csv', 2) == 80\n\n    def test_calculate_average_3(self):\n        assert calculate_average('test3.csv', 2) == 8\n\n    def test_calculate_average_4(self):\n        assert calculate_average('test4.csv', 2) == 800\n\n    def test_calculate_average_5(self):\n        assert calculate_average('test5.csv', 2) == 0\n\n    def test_calculate_average_6(self):\n        assert calculate_average('test6.csv', 2) == 0\n\n    def test_calculate_average_7(self):\n        assert calculate_average('test7.csv', 2) == 15500\n", "required_packages": ["csv"]}
{"id": "2", "title": "E-commerce Order System", "description": "Create an `Order` class for a simple e-commerce system.  This class should manage order details such as order ID, items (a list of dictionaries with product name and price), total price, and order status (initially \"unpaid\").", "language": "python", "difficulty": "easy", "category": "Software Engineering", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nImplement a simple e-commerce order system.\n\nRequirements:\n\nImplement an Order class with the following attributes:\norder_id: The order number, which is a string.\nitems: The list of products in the order, each product is a dictionary containing the product name and price.\ntotal_price: The total price of the order, which is a floating point number.\nstatus: The status of the order, which is a string, the initial status is \"unpaid\".\nImplement the following methods:\nadd_item(item_name, item_price): Add a product to the order, the parameters are the product name and price.\nremove_item(item_name): Remove the specified product from the order, the parameter is the product name.\ncalculate_total_price(): Calculate the total price of the order and update the total_price attribute.\npay_order(): Pay for the order, update the order status to \"paid\".\ncancel_order(): Cancel the order, update the order status to \"cancelled\".\nview_order(): Output the detailed information of the order, including the order number, product list, total price and status, follow the following format:\nOrder number: 20231218\nProduct list:\n- Product 1: \u00a510.5\n- Product 2: \u00a520.3\nTotal price: \u00a530.8\nStatus: Unpaid\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass TestOrder:\n    def test_add_item(self):\n        order = Order(\"20231218\")\n        order.add_item(\"\u5546\u54c11\", 10.5)\n        assert len(order.items) == 1\n        assert order.items[0][\"name\"] == \"\u5546\u54c11\"\n        assert order.items[0][\"price\"] == 10.5\n\n", "llm_code": "class Order:\n    def __init__(self, order_id):\n        self.order_id = order_id\n        self.items = []\n        self.total_price = 0.0\n        self.status = \"unpaid\"\n\n    def add_item(self, item_name, item_price):\n        self.items.append({\"name\": item_name, \"price\": item_price})\n\n    def remove_item(self, item_name):\n        for item in self.items:\n            if item[\"name\"] == item_name:\n                self.items.remove(item)\n                break\n\n    def calculate_total_price(self):\n        self.total_price = sum(item[\"price\"] for item in self.items)\n\n    def pay_order(self):\n        self.status = \"paid\"\n\n    def cancel_order(self):\n        self.status = \"cancelled\"\n\n    def view_order(self):\n        print(f\"Order number: {self.order_id}\")\n        print(\"Product list:\")\n        for item in self.items:\n            print(f\"- {item['name']}: \u00a5{item['price']}\")\n        print(f\"Total price: \u00a5{self.total_price}\")\n        print(f\"Status: {self.status}\")", "correct_code": "class Order:\n    def __init__(self, order_id):\n        self.order_id = order_id\n        self.items = []\n        self.total_price = 0.0\n        self.status = \"\u672a\u652f\u4ed8\"\n\n    def add_item(self, item_name, item_price):\n        if not isinstance(item_price, (int, float)) or item_price <= 0:\n            return \"\u5546\u54c1\u4ef7\u683c\u5fc5\u987b\u662f\u6b63\u6570\"\n\n        item = {\"name\": item_name, \"price\": item_price}\n        self.items.append(item)\n\n    def remove_item(self, item_name):\n        for item in self.items:\n            if item[\"name\"] == item_name:\n                self.items.remove(item)\n                break\n        else:\n            return \"\u8be5\u5546\u54c1\u4e0d\u5b58\u5728\u4e8e\u8ba2\u5355\u4e2d\"\n\n    def calculate_total_price(self):\n        self.total_price = sum(item[\"price\"] for item in self.items)\n\n    def pay_order(self):\n        if not self.items:\n            return \"\u8ba2\u5355\u4e2d\u6ca1\u6709\u5546\u54c1\"\n        self.status = \"\u5df2\u652f\u4ed8\"\n\n    def cancel_order(self):\n        self.status = \"\u5df2\u53d6\u6d88\"\n\n    def view_order(self):\n        print(\"\u8ba2\u5355\u7f16\u53f7\uff1a\", self.order_id)\n        print(\"\u5546\u54c1\u5217\u8868\uff1a\")\n        for item in self.items:\n            print(\"- {}: \uffe5{}\".format(item[\"name\"], item[\"price\"]))\n        print(\"\u603b\u4ef7\u683c\uff1a\uffe5{}\".format(self.total_price))\n        print(\"\u72b6\u6001\uff1a\", self.status)", "test_code": "\n\nclass TestOrder:\n    def test_remove_item(self):\n        order = Order(\"20231218\")\n        order.add_item(\"\u5546\u54c11\", 10.5)\n        order.remove_item(\"\u5546\u54c11\")\n        assert len(order.items) == 0\n\n    def test_calculate_total_price(self):\n        order = Order(\"20231218\")\n        order.add_item(\"\u5546\u54c11\", 10.5)\n        order.add_item(\"\u5546\u54c12\", 20.3)\n        order.calculate_total_price()\n        assert order.total_price == 30.8\n\n    def test_remove_item_(self):\n        order = Order(\"20231218\")\n        order.add_item(\"\u5546\u54c11\", 10.5)\n        order.remove_item(\"\u5546\u54c11\")\n        assert len(order.items) == 0\n\n    def test_pay_order(self):\n        order = Order(\"20231218\")\n        order.pay_order()\n        assert order.status == \"\u672a\u652f\u4ed8\"\n\n    def test_pay_order_(self):\n        order = Order(\"20231210\")\n        assert order.status == \"\u672a\u652f\u4ed8\"\n\n    def test_cancel_order(self):\n        order = Order(\"20231218\")\n        order.cancel_order()\n        assert order.status == \"\u5df2\u53d6\u6d88\"\n\n    def test_view_order(self, capsys):\n        order = Order(\"20231218\")\n        order.add_item(\"\u5546\u54c11\", 10.5)\n        order.add_item(\"\u5546\u54c12\", 20.3)\n        order.calculate_total_price()\n        order.view_order()\n        captured = capsys.readouterr()\n        expected_output = (\n            \"\u8ba2\u5355\u7f16\u53f7\uff1a 20231218\\n\"\n            \"\u5546\u54c1\u5217\u8868\uff1a\\n\"\n            \"- \u5546\u54c11: \uffe510.5\\n\"\n            \"- \u5546\u54c12: \uffe520.3\\n\"\n            \"\u603b\u4ef7\u683c\uff1a\uffe530.8\\n\"\n            \"\u72b6\u6001\uff1a \u672a\u652f\u4ed8\\n\"\n        )\n        assert captured.out == expected_output\n", "required_packages": []}
{"id": "20", "title": "City Highest Temperatures", "description": "You are given a folder containing multiple CSV files. Each file represents the daily temperature records of a city in 2022.  Each CSV has two columns: \"Date\" and \"Temperature\", with the first row being the header. The temperature values are integers.", "language": "python", "difficulty": "medium", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nThere are multiple CSV files in the data folder, each file has two columns, containing the daily temperature records of a certain city in 2022. The first row is the title, which are Date and Temperature. The temperature value is an integer. I need to find out the highest temperature value and the corresponding date of each city in that year, and save the results to a new CSV file. The result CSV consists of three columns, including city, highest temperature, and date. Note that if the highest temperature is the same for multiple days, keep all dates that reach the highest temperature. How can I use the pandas library's dataframe to complete this task?\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testfind_max_temperature:\n    def test_single_file_single_max(self, tmpdir):\n        data = \"Date,Temperature\\n2022-01-01,10\\n2022-01-02,20\\n2022-01-03,30\"\n        p = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p.write(data)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert output_file.read() == \"City,Max_Temperature,Date\\ncity1,30,2022-01-03\\n\"\n\n", "llm_code": "import pandas as pd\nimport os\n\ndef find_max_temperature(data_folder, output_file):\n    \"\"\"\n    Finds the highest temperature and corresponding date for each city from CSV files\n    in the data folder and saves the results to a new CSV file.\n\n    Args:\n        data_folder (str): Path to the folder containing the CSV files.\n        output_file (str): Path to the output CSV file.\n    \"\"\"\n\n    results = []\n    for filename in os.listdir(data_folder):\n        if filename.endswith(\".csv\"):\n            city = filename[:-4]  # Extract city name from filename\n            file_path = os.path.join(data_folder, filename)\n            df = pd.read_csv(file_path)\n            max_temp = df['Temperature'].max()\n            max_temp_dates = df[df['Temperature'] == max_temp]['Date'].tolist()\n            \n            for date in max_temp_dates:\n                results.append({'City': city, 'Max_Temperature': max_temp, 'Date': date})\n\n    results_df = pd.DataFrame(results)\n    results_df.to_csv(output_file, index=False, header=['City', 'Max_Temperature', 'Date'])", "correct_code": "import os\nimport pandas as pd\n\n\ndef find_max_temperature(folder_path, output_file):\n    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n    \n    result_df = pd.DataFrame(columns=['City', 'Max_Temperature', 'Date'])\n    \n    for csv_file in csv_files:\n        file_path = os.path.join(folder_path, csv_file)\n        df = pd.read_csv(file_path)\n    \n        city_name = csv_file[:-4]\n    \n        # \u627e\u5230\u6700\u9ad8\u6c14\u6e29\u7684\u503c\n        max_temp = df['Temperature'].max()\n    \n        # \u627e\u5230\u6240\u6709\u6700\u9ad8\u6c14\u6e29\u7684\u65e5\u671f\n        max_temp_dates = df.loc[df['Temperature'] == max_temp, 'Date'].tolist()\n    \n        # \u5c06\u7ed3\u679c\u6dfb\u52a0\u5230result_df\n        for date in max_temp_dates:\n            result_df = result_df._append({'City': city_name,\n                                           'Max_Temperature': max_temp,\n                                           'Date': date}, ignore_index=True)\n    \n    result_df.to_csv(output_file, index=False)", "test_code": "import os\n\nclass Testfind_max_temperature:\n    def test_single_file_multiple_max(self, tmpdir):\n        data = \"Date,Temperature\\n2022-01-01,30\\n2022-01-02,20\\n2022-01-03,30\"\n        p = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p.write(data)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city1,30,2022-01-01' in output_file.read() and 'city1,30,2022-01-03' in output_file.read()\n\n    def test_multiple_files_single_max(self, tmpdir):\n        data1 = \"Date,Temperature\\n2022-01-01,10\\n2022-01-02,20\\n2022-01-03,30\"\n        data2 = \"Date,Temperature\\n2022-01-01,20\\n2022-01-02,30\\n2022-01-03,40\"\n        p1 = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p1.write(data1)\n        p2 = tmpdir.join(\"data\").join(\"city2.csv\")\n        p2.write(data2)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city1,30,2022-01-03' in output_file.read() and 'city2,40,2022-01-03' in output_file.read()\n\n    def test_multiple_files_multiple_max(self, tmpdir):\n        data1 = \"Date,Temperature\\n2022-01-01,30\\n2022-01-02,20\\n2022-01-03,30\"\n        data2 = \"Date,Temperature\\n2022-01-01,40\\n2022-01-02,30\\n2022-01-03,40\"\n        p1 = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p1.write(data1)\n        p2 = tmpdir.join(\"data\").join(\"city2.csv\")\n        p2.write(data2)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city1,30,2022-01-01' in output_file.read() and 'city1,30,2022-01-03' in output_file.read() and 'city2,40,2022-01-01' in output_file.read() and 'city2,40,2022-01-03' in output_file.read()\n\n    def test_no_csv_files(self, tmpdir):\n        tmpdir.mkdir(\"data\")\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert output_file.read() == \"City,Max_Temperature,Date\\n\"\n\n    def test_empty_csv_file(self, tmpdir):\n        p = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p.write(\"Date,Temperature\\n\")\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert output_file.read() == \"City,Max_Temperature,Date\\n\"\n\n    def test_single_file_single_max_boundary(self, tmpdir):\n        data = \"Date,Temperature\\n2022-01-01,999999\\n2022-01-02,20\\n2022-01-03,30\"\n        p = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p.write(data)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city1,999999,2022-01-01' in output_file.read()\n\n    def test_single_file_multiple_max_boundary(self, tmpdir):\n        data = \"Date,Temperature\\n2022-01-01,999999\\n2022-01-02,20\\n2022-01-03,999999\"\n        p = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p.write(data)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city1,999999,2022-01-01' in output_file.read() and 'city1,999999,2022-01-03' in output_file.read()\n\n    def test_multiple_files_single_max_boundary(self, tmpdir):\n        data1 = \"Date,Temperature\\n2022-01-01,10\\n2022-01-02,20\\n2022-01-03,30\"\n        data2 = \"Date,Temperature\\n2022-01-01,999999\\n2022-01-02,30\\n2022-01-03,40\"\n        p1 = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p1.write(data1)\n        p2 = tmpdir.join(\"data\").join(\"city2.csv\")\n        p2.write(data2)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city2,999999,2022-01-01' in output_file.read() and 'city1,30,2022-01-03' in output_file.read()\n\n    def test_multiple_files_multiple_max_boundary(self, tmpdir):\n        data1 = \"Date,Temperature\\n2022-01-01,999999\\n2022-01-02,20\\n2022-01-03,999999\"\n        data2 = \"Date,Temperature\\n2022-01-01,999999\\n2022-01-02,30\\n2022-01-03,999999\"\n        p1 = tmpdir.mkdir(\"data\").join(\"city1.csv\")\n        p1.write(data1)\n        p2 = tmpdir.join(\"data\").join(\"city2.csv\")\n        p2.write(data2)\n        output_file = tmpdir.join(\"output.csv\")\n        find_max_temperature(str(tmpdir.join(\"data\")), str(output_file))\n        assert 'city2,999999,2022-01-01' in output_file.read() and 'city1,999999,2022-01-01' in output_file.read() and 'city2,999999,2022-01-03' in output_file.read() and 'city1,999999,2022-01-03' in output_file.read()", "required_packages": ["os", "pandas"]}
{"id": "21", "title": "Merging and Smoothing Time Series Data", "description": "You are given a list of CSV files, `file_list`. Each file contains time-series data with a timestamp and multiple numerical features (e.g., `feature1`, `feature2`, `feature3`).  Your task is to read the data from all CSV files, merge them into a single dataset based on the timestamp, and then calculate the moving average for each numerical feature.", "language": "python", "difficulty": "medium", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nRead data from multiple CSV files, each file representing a data source. Merge these data according to the timestamp, and then calculate the moving average of the merged data.\nThe format of data.csv is\ntimestamp,feature1,feature2,feature3\n2023-03-15 14:30:00,10,20,30\n2023-03-15 14:35:00,11,21,31\n2023-03-15 14:40:00,12,22,32\n...\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testmerge_and_smooth_data:\n    def test_merge_and_smooth_data_1(self):\n        data1 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:30:00', '2023-03-15 14:35:00', '2023-03-15 14:40:00'],\n            'feature1': [10, 11, 12],\n            'feature2': [20, 21, 22],\n            'feature3': [30, 31, 32]\n        })\n        data1.to_csv('data1.csv.csv', index=False)\n        data2 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:45:00', '2023-03-15 14:50:00', '2023-03-15 14:55:00'],\n            'feature1': [13, 14, 15],\n            'feature2': [23, 24, 25],\n            'feature3': [33, 34, 35]\n        })\n        data2.to_csv('data2.csv', index=False)\n        assert merge_and_smooth_data(['data1.csv.csv', 'data2.csv'], 2).tolist() == [[11.5, 21.5, 31.5], [12.5, 22.5, 32.5], [13.5, 23.5, 33.5], [14.5, 24.5, 34.5]]\n\n", "llm_code": "import pandas as pd\n\ndef merge_and_smooth_data(file_list, window_size):\n    \"\"\"\n    Reads data from multiple CSV files, merges them based on timestamp,\n    and calculates the moving average of the merged data.\n\n    Args:\n        file_list (list): A list of CSV file paths.\n        window_size (int): The size of the moving average window.\n\n    Returns:\n        pandas.DataFrame: A DataFrame containing the moving average of the merged data.\n    \"\"\"\n    dfs = []\n    for file in file_list:\n        df = pd.read_csv(file)\n        dfs.append(df)\n\n    merged_df = pd.concat(dfs, ignore_index=True)\n    merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'])\n    merged_df = merged_df.sort_values(by='timestamp')\n    merged_df = merged_df.set_index('timestamp')\n\n    numeric_columns = merged_df.select_dtypes(include=['number']).columns\n    smoothed_data = merged_df[numeric_columns].rolling(window=window_size).mean().dropna()\n\n    return smoothed_data", "correct_code": "import pandas as pd\nimport torch\n\ndef merge_and_smooth_data(filenames, window_size):\n    dfs = [pd.read_csv(filename) for filename in filenames]\n    merged_df = pd.concat(dfs).sort_values(by='timestamp')\n\n    tensor = torch.tensor(merged_df.drop(columns=['timestamp']).values)\n\n    cumsum = tensor.cumsum(dim=0)\n    sliding_avg = (cumsum[window_size:] - cumsum[:-window_size]) / float(window_size)\n    return sliding_avg", "test_code": "import pandas as pd\n\nclass Testmerge_and_smooth_data:\n    def test_merge_and_smooth_data_2(self):\n        data1 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:30:00', '2023-03-15 14:35:00', '2023-03-15 14:40:00'],\n            'feature1': [10, 11, 12],\n            'feature2': [20, 21, 22],\n            'feature3': [30, 31, 32]\n        })\n        data1.to_csv('data1.csv.csv', index=False)\n        data2 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:45:00', '2023-03-15 14:50:00', '2023-03-15 14:55:00'],\n            'feature1': [13, 14, 15],\n            'feature2': [23, 24, 25],\n            'feature3': [33, 34, 35]\n        })\n        data2.to_csv('data2.csv', index=False)\n        assert merge_and_smooth_data(['data1.csv.csv', 'data2.csv'], 3).tolist() == [[12.0, 22.0, 32.0], [13.0, 23.0, 33.0], [14.0, 24.0, 34.0]]\n\n    def test_merge_and_smooth_data_3(self):\n        data1 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:30:00', '2023-03-15 14:35:00', '2023-03-15 14:40:00'],\n            'feature1': [10, 11, 12],\n            'feature2': [20, 21, 22],\n            'feature3': [30, 31, 32]\n        })\n        data1.to_csv('data1.csv.csv', index=False)\n        assert merge_and_smooth_data(['data1.csv.csv'], 2).tolist() == [[11.5, 21.5, 31.5]]\n\n    def test_merge_and_smooth_data_4(self):\n        data1 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:30:00', '2023-03-15 14:35:00', '2023-03-15 14:40:00'],\n            'feature1': [10, 11, 12],\n            'feature2': [20, 21, 22],\n            'feature3': [30, 31, 32]\n        })\n        data1.to_csv('data1.csv.csv', index=False)\n        assert merge_and_smooth_data(['data1.csv.csv'], 1).tolist() == [[11.0, 21.0, 31.0], [12.0, 22.0, 32.0]]\n\n    def test_merge_and_smooth_data_5(self):\n        data1 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:30:00'],\n            'feature1': [10],\n            'feature2': [20],\n            'feature3': [30]\n        })\n        data1.to_csv('data1.csv.csv', index=False)\n        assert merge_and_smooth_data(['data1.csv.csv'], 1).tolist() == []\n\n    def test_merge_and_smooth_data_6(self):\n        data1 = pd.DataFrame({\n            'timestamp': ['2023-03-15 14:30:00'],\n            'feature1': [10],\n            'feature2': [20],\n            'feature3': [30]\n        })\n        data1.to_csv('data1.csv.csv', index=False)\n        assert merge_and_smooth_data(['data1.csv.csv'], 2).tolist() == []", "required_packages": ["pandas", "torch"]}
{"id": "22", "title": "Image Resizing and Renaming", "description": "You are given a folder containing images. Your task is to write a Python program that processes these images in the following way:", "language": "python", "difficulty": "medium", "category": "Software Engineering", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nUse Python to convert the images in the folder to RGB format, then number the images from smallest to largest, and change the resolution of all images to a specified resolution (x, y). Save the modified folder to the given path. Then output the resolution of all images in the modified folder.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testresize_and_rename_images:\n    def test_resize_and_rename_images_1(self, capsys):\n        resize_and_rename_images('test1/input', 'test1/output', (800, 600))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n001.jpg: 800 x 600\\n002.jpg: 800 x 600\\n003.jpg: 800 x 600\\n\"\n\n", "llm_code": "import os\nfrom PIL import Image\n\ndef resize_and_rename_images(input_folder, output_folder, resolution):\n    \"\"\"\n    Converts images in a folder to RGB, resizes them, and renames them sequentially.\n\n    Args:\n        input_folder: Path to the folder containing the original images.\n        output_folder: Path to the folder where the modified images will be saved.\n        resolution: A tuple (width, height) specifying the desired resolution.\n    \"\"\"\n\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    image_paths = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n    image_paths.sort()  # Sort images alphabetically\n\n    modified_images_resolutions = {}\n    \n    for i, image_path in enumerate(image_paths):\n        try:\n            img = Image.open(image_path).convert(\"RGB\")\n            img = img.resize(resolution)\n            new_filename = f\"{i+1:03d}.jpg\"  # Format as 001.jpg, 002.jpg, etc.\n            new_filepath = os.path.join(output_folder, new_filename)\n            img.save(new_filepath)\n            modified_images_resolutions[new_filename] = resolution\n        except Exception as e:\n            print(f\"Error processing {image_path}: {e}\")\n\n    print(\"Modified images resolutions:\")\n    for filename, resolution in modified_images_resolutions.items():\n        print(f\"{filename}: {resolution[0]} x {resolution[1]}\")", "correct_code": "from PIL import Image\nimport os\n\n\ndef resize_and_rename_images(input_folder, output_folder, target_resolution=(800, 600)):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n    image_files.sort()  # \u6309\u6587\u4ef6\u540d\u6392\u5e8f\n    for i, image_file in enumerate(image_files):\n        input_path = os.path.join(input_folder, image_file)\n        output_path = os.path.join(output_folder, f\"{i + 1:03d}.jpg\")  # \u683c\u5f0f\u5316\u6587\u4ef6\u540d\n\n        # \u6253\u5f00\u56fe\u7247\n        img = Image.open(input_path)\n\n        # \u8f6c\u6362\u4e3aRGB\u6a21\u5f0f\n        img = img.convert(\"RGB\")\n\n        # \u7edf\u4e00\u5206\u8fa8\u7387\n        img = img.resize(target_resolution, Image.LANCZOS)\n\n        # \u4fdd\u5b58\u56fe\u7247\n        img.save(output_path)\n\n    print(\"Modified images resolutions:\")\n    print_resolutions(output_folder)\n    return output_folder\n\n\ndef print_resolutions(folder_path):\n    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n    image_files.sort()\n\n    for image_file in image_files:\n        image_path = os.path.join(folder_path, image_file)\n        img = Image.open(image_path)\n        resolution = img.size\n        print(f\"{image_file}: {resolution[0]} x {resolution[1]}\")\n\n\nresize_and_rename_images('test6/input', 'test6/output', (2560, 1440))", "test_code": "from PIL import Image\n\nclass Testresize_and_rename_images:\n    def test_resize_and_rename_images_2(self, capsys):\n        resize_and_rename_images('test2/input', 'test2/output', (1024, 768))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n001.jpg: 1024 x 768\\n002.jpg: 1024 x 768\\n\"\n\n    def test_resize_and_rename_images_3(self, capsys):\n        resize_and_rename_images('test3/input', 'test3/output', (1920, 1080))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n001.jpg: 1920 x 1080\\n\"\n\n    def test_resize_and_rename_images_4(self, capsys):\n        resize_and_rename_images('test4/input', 'test4/output', (1280, 720))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n001.jpg: 1280 x 720\\n002.jpg: 1280 x 720\\n003.jpg: 1280 x 720\\n004.jpg: 1280 x 720\\n005.jpg: 1280 x 720\\n006.jpg: 1280 x 720\\n007.jpg: 1280 x 720\\n008.jpg: 1280 x 720\\n\"\n\n    def test_resize_and_rename_images_5(self, capsys):\n        resize_and_rename_images('test5/input', 'test5/output', (1600, 900))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n001.jpg: 1600 x 900\\n002.jpg: 1600 x 900\\n\"\n\n    def test_resize_and_rename_images_6(self, capsys):\n        resize_and_rename_images('test6/input', 'test6/output', (2560, 1440))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n001.jpg: 2560 x 1440\\n002.jpg: 2560 x 1440\\n003.jpg: 2560 x 1440\\n\"\n\n    def test_resize_and_rename_images_7(self, capsys):\n        resize_and_rename_images('test7/input', 'test7/output', (800, 600))\n        captured = capsys.readouterr()\n        assert captured.out == \"Modified images resolutions:\\n\"\n", "required_packages": ["os", "PIL"]}
{"id": "23", "title": "Implementing Focal Loss", "description": "Implement the focal loss function, a variation of cross-entropy loss that addresses class imbalance by down-weighting well-classified examples.  You will be given two hyperparameters, `alpha` and `gamma`. The `forward` function of your implementation will take `inputs` (model predictions) and `targets` (ground truth labels).  `inputs` is a tensor of arbitrary shape representing predicted probabilities (logits). `targets` is a tensor of the same shape as `inputs` containing binary labels (0 or 1). Your function should compute and return the mean focal loss as a scalar tensor.", "language": "python", "difficulty": "medium", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nPlease implement focal loss, a method proposed in 2017. Specifically, initialize two parameters alpha and gamma. The forward function receives inputs and targets representing the model output and GT.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Test__init__:\n    def test_focal_loss_1(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 1.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0649), atol=1e-4)\n\n", "llm_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Compute the focal loss between `inputs` and `targets`.\n\n        Args:\n            inputs: A float tensor of arbitrary shape.\n                    The predictions for each example.\n            targets: A float tensor with the same shape as inputs. Stores the binary\n                     classification label for each element in `inputs`\n                    (0 for the negative class and 1 for the positive class).\n\n        Returns:\n            Loss tensor\n        \"\"\"\n        logpt = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n        pt = torch.exp(-logpt)\n        loss = -self.alpha * (1 - pt) ** self.gamma * targets * logpt - (1 - self.alpha) * (1 - pt) ** self.gamma * (1 - targets) * logpt\n        return torch.mean(loss)", "correct_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        \n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)  \n        focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        return focal_loss.mean()\n\n\ncriterion = FocalLoss(alpha=0.25, gamma=2.0)\ninputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\ntargets = torch.tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n\nloss = criterion(inputs, targets).detach()\nprint(loss)", "test_code": "import torch\nimport torch.nn as nn\n\nclass Test__init__:\n    def test_focal_loss_2(self):\n        criterion = FocalLoss(alpha=0.5, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 1.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.1297), atol=1e-4)\n\n    def test_focal_loss_3(self):\n        criterion = FocalLoss(alpha=0.25, gamma=3.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 1.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0414), atol=1e-4)\n\n    def test_focal_loss_4(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0649), atol=1e-4)\n\n    def test_focal_loss_5(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0649), atol=1e-4)\n\n    def test_focal_loss_6(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0524), atol=1e-4)\n\n    def test_focal_loss_7(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0777), atol=1e-4)\n\n    def test_focal_loss_8(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0520), atol=1e-4)\n\n    def test_focal_loss_9(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.1098), atol=1e-4)\n\n    def test_focal_loss_10(self):\n        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n        inputs = torch.tensor([0.1, 0.2, 0.4, 0.8, 1.2, -0.1, -0.2, -0.4, -0.8, -1.2], requires_grad=True)\n        targets = torch.tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n        assert torch.allclose(criterion(inputs, targets).detach(), torch.tensor(0.0200), atol=1e-4)", "required_packages": ["torch"]}
{"id": "24", "title": "Copy File to Folder", "description": "You are given two paths: `source_path` (a file path) and `destination_folder` (a folder path). Write a Python function `copy_and_move_file` that copies the file at `source_path` to `destination_folder`.  If the file specified by `source_path` does not exist, print \"File not exist.\" to the console. Handle potential errors like permission issues gracefully.  You do *not* need to delete the original file at `source_path` - only copy it.", "language": "python", "difficulty": "easy", "category": "Operation System", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nUse a Python function to accept two path parameters, copy the file pointed to by the first path parameter and move it to the folder pointed to by the second path parameter. If the file does not exist, output \"File not exist.\".\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcopy_and_move_file:\n    def test_copy_and_move_file_1(self):\n        copy_and_move_file('test1/test.txt', 'test1/target')\n        assert os.path.exists('test1/target/test.txt')\n\n", "llm_code": "import os\nimport shutil\n\ndef copy_and_move_file(source_path, destination_folder):\n    \"\"\"\n    Copies a file from the source path to the destination folder.\n\n    Args:\n        source_path: The path to the file to copy.\n        destination_folder: The path to the folder where the file should be copied.\n    \"\"\"\n    try:\n        shutil.copy(source_path, destination_folder)\n        # Construct the destination path\n        destination_path = os.path.join(destination_folder, os.path.basename(source_path))\n        # If file exist, do nothing\n        # shutil.move(source_path, destination_path)\n    except FileNotFoundError:\n        print(\"File not exist.\")\n    except OSError as e:\n        print(f\"Error moving/copying file: {e}\")\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")", "correct_code": "import os\nimport shutil\n\n\ndef copy_and_move_file(source_path, destination_directory):\n    # \u83b7\u53d6\u6e90\u6587\u4ef6\u7684\u6587\u4ef6\u540d\n    file_name = os.path.basename(source_path)\n\n    # \u6784\u5efa\u76ee\u6807\u8def\u5f84\n    destination_path = os.path.join(destination_directory, file_name)\n\n    # \u68c0\u67e5\u6e90\u6587\u4ef6\u662f\u5426\u5b58\u5728\n    if os.path.exists(source_path):\n        # \u590d\u5236\u6587\u4ef6\n        shutil.copy(source_path, destination_path)\n    else:\n        print(\"File not exist.\")", "test_code": "import os\n\nclass Testcopy_and_move_file:\n    def test_copy_and_move_file_2(self, capsys):\n        copy_and_move_file('test2/test.txt', 'test2/target')\n        captured = capsys.readouterr()\n        assert captured.out == \"File not exist.\\n\"\n\n    def test_copy_and_move_file_3(self):\n        copy_and_move_file('test3/source/test.txt', 'test3')\n        assert os.path.exists('test3/test.txt')\n\n    def test_copy_and_move_file_4(self):\n        with pytest.raises(FileNotFoundError):\n            copy_and_move_file('test4/test.txt', 'test4/target')\n\n    def test_copy_and_move_file_5(self):\n        copy_and_move_file('test5/source/test.txt', 'test5/target')\n        assert os.path.exists('test5/target/test.txt')\n\n    def test_copy_and_move_file_6(self):\n        copy_and_move_file('test6/test.txt', 'test6/target')\n        assert os.path.exists('test6/target/test.txt')", "required_packages": ["os", "shutil"]}
{"id": "25", "title": "Sparse Matrix to NumPy Array", "description": "Given the file path to a compressed sparse row matrix stored in `.npz` format, load the matrix, convert it to a dense NumPy `ndarray`, and save the resulting array to a `.npy` file.  You will need to use the `scipy.sparse` library for loading and converting the sparse matrix, and the `numpy` library for saving the final array.  The function should take two string arguments: `npz_file` (the path to the input `.npz` file) and `npy_file` (the path where the `.npy` file should be saved).", "language": "python", "difficulty": "easy", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nConvert a scipy.sparse.csr_matrix to ndarray and save it in a npy file,\nwhere the initial csr_matrix is saved in a npz file and needs to be loaded before conversion.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcsr_to_numpy:\n    def test_csr_to_numpy_1(self):\n        csr_to_numpy('test1/test.npz', 'test1/test.npy')\n        assert np.array_equal(np.load('test1/test.npy'), np.load('test1/label.npy'))\n\n", "llm_code": "import scipy.sparse\nimport numpy as np\n\ndef csr_to_numpy(npz_file, npy_file):\n    \"\"\"\n    Convert a scipy.sparse.csr_matrix to ndarray and save it in a npy file.\n\n    Args:\n        npz_file (str): Path to the npz file containing the csr_matrix.\n        npy_file (str): Path to save the ndarray in npy format.\n    \"\"\"\n    csr_matrix = scipy.sparse.load_npz(npz_file)\n    ndarray = csr_matrix.toarray()\n    np.save(npy_file, ndarray)", "correct_code": "import numpy as np\nimport scipy.sparse as sp\n\n\ndef csr_to_numpy(input_file, output_file):\n    input_arr_csr = sp.load_npz(input_file)\n    input_arr = input_arr_csr.toarray()\n    np.save(output_file, input_arr)", "test_code": "import numpy as np\nimport scipy.sparse as sp\n\n\nclass Testcsr_to_numpy:\n    def test_csr_to_numpy_2(self):\n        csr_to_numpy('test2/test.npz', 'test2/test.npy')\n        assert np.array_equal(np.load('test2/test.npy'), np.load('test2/label.npy'))\n\n    def test_csr_to_numpy_3(self):\n        csr_to_numpy('test3/test.npz', 'test3/test.npy')\n        assert np.array_equal(np.load('test3/test.npy'), np.load('test3/label.npy'))\n\n    def test_csr_to_numpy_4(self):\n        csr_to_numpy('test4/test.npz', 'test4/test.npy')\n        assert np.array_equal(np.load('test4/test.npy'), np.load('test4/label.npy'))\n\n    def test_csr_to_numpy_5(self):\n        csr_to_numpy('test5/test.npz', 'test5/test.npy')\n        assert np.array_equal(np.load('test5/test.npy'), np.load('test5/label.npy'))\n\n    def test_csr_to_numpy_6(self):\n        csr_to_numpy('test6/test.npz', 'test6/test.npy')\n        assert np.array_equal(np.load('test6/test.npy'), np.load('test6/label.npy'))\n\n    def test_csr_to_numpy_7(self):\n        csr_to_numpy('test7/test.npz', 'test7/test.npy')\n        assert np.array_equal(np.load('test7/test.npy'), np.load('test7/label.npy'))\n\n    def test_csr_to_numpy_8(self):\n        csr_to_numpy('test8/test.npz', 'test8/test.npy')\n        assert np.array_equal(np.load('test8/test.npy'), np.load('test8/label.npy'))\n\n    def test_csr_to_numpy_9(self):\n        csr_to_numpy('test9/test.npz', 'test9/test.npy')\n        assert np.array_equal(np.load('test9/test.npy'), np.load('test9/label.npy'))", "required_packages": ["numpy", "scipy"]}
{"id": "26", "title": "Sparse Ndarray to CSR Matrix Conversion", "description": "You are given the path to an `.npy` file containing a sparse NumPy ndarray.  Your task is to load this array, convert it into a Compressed Sparse Row (CSR) matrix using `scipy.sparse`, and then save the resulting CSR matrix into an `.npz` file.  The function should take two string arguments: `npy_path` (the path to the input `.npy` file) and `npz_path` (the path to the output `.npz` file).  No return value is expected; the function should simply perform the conversion and save the result.", "language": "python", "difficulty": "easy", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nConvert a sparse ndarray into a scipy.sparse.csr_matrix and save it in an npz file, where the initial ndarray is saved in an npy file and needs to be loaded before conversion.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testnumpy_to_csr:\n    def test_case1(self):\n        numpy_to_csr('test1/test.npy', 'test1/test.npz')\n        test_arr = sp.load_npz('test1/test.npz').toarray()\n        label_arr = sp.load_npz('test1/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n", "llm_code": "import numpy as np\nimport scipy.sparse as sp\n\ndef numpy_to_csr(npy_path, npz_path):\n    \"\"\"\n    Converts a sparse ndarray from an npy file to a csr_matrix and saves it as an npz file.\n\n    Args:\n        npy_path (str): Path to the input npy file.\n        npz_path (str): Path to the output npz file.\n    \"\"\"\n    arr = np.load(npy_path)\n    csr_matrix = sp.csr_matrix(arr)\n    sp.save_npz(npz_path, csr_matrix)", "correct_code": "import numpy as np\nimport scipy.sparse as sp\n\ndef numpy_to_csr(input_file, output_file):\n    input_arr = np.load(input_file)\n    input_arr_csr = sp.csr_matrix(input_arr)\n    sp.save_npz(output_file, input_arr_csr)", "test_code": "import numpy as np\nimport scipy.sparse as sp\n\n\nclass Testnumpy_to_csr:\n    def test_case2(self):\n        numpy_to_csr('test2/test.npy', 'test2/test.npz')\n        test_arr = sp.load_npz('test2/test.npz').toarray()\n        label_arr = sp.load_npz('test2/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case3(self):\n        numpy_to_csr('test3/test.npy', 'test3/test.npz')\n        test_arr = sp.load_npz('test3/test.npz').toarray()\n        label_arr = sp.load_npz('test3/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case4(self):\n        numpy_to_csr('test4/test.npy', 'test4/test.npz')\n        test_arr = sp.load_npz('test4/test.npz').toarray()\n        label_arr = sp.load_npz('test4/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case5(self):\n        numpy_to_csr('test5/test.npy', 'test5/test.npz')\n        test_arr = sp.load_npz('test5/test.npz').toarray()\n        label_arr = sp.load_npz('test5/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case6(self):\n        numpy_to_csr('test6/test.npy', 'test6/test.npz')\n        test_arr = sp.load_npz('test6/test.npz').toarray()\n        label_arr = sp.load_npz('test6/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case7(self):\n        numpy_to_csr('test7/test.npy', 'test7/test.npz')\n        test_arr = sp.load_npz('test7/test.npz').toarray()\n        label_arr = sp.load_npz('test7/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case8(self):\n        numpy_to_csr('test8/test.npy', 'test8/test.npz')\n        test_arr = sp.load_npz('test8/test.npz').toarray()\n        label_arr = sp.load_npz('test8/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)\n\n    def test_case9(self):\n        numpy_to_csr('test9/test.npy', 'test9/test.npz')\n        test_arr = sp.load_npz('test9/test.npz').toarray()\n        label_arr = sp.load_npz('test9/label.npz').toarray()\n        assert np.array_equal(test_arr, label_arr)", "required_packages": ["numpy", "scipy"]}
{"id": "27", "title": "Calculate and Save Attention Scores", "description": "You are given two NumPy arrays, `array1` and `array2`, both of shape (X, Y, Z).  Your task is to convert these arrays into single-precision floating-point tensors using PyTorch.  Reshape `array2` to (X, Z, Y). Then, calculate the attention scores by performing matrix multiplication between `array1` and the reshaped `array2`. The result will be a tensor representing the attention scores. Finally, write these attention scores into a file named \"result.txt\", with each score on a new line. The function should also return the calculated attention scores tensor.", "language": "python", "difficulty": "medium", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nConvert two numpy arrays of shape (X, Y, Z) into tensor type and single-precision floating point type. Change the shape of one of them to (X, Z, Y). Calculate the attention scores of these two matrices and output the results. Then write the results into a file named result.txt.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testprocess_tensor:\n    def test_process_tensor_1(self):\n        array1 = np.ones((3, 9, 5))\n        array2 = np.ones((3, 9, 5))\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((3, 9, 9))*5))\n\n", "llm_code": "import numpy as np\nimport torch\n\ndef process_tensor(array1, array2):\n    \"\"\"\n    Converts two numpy arrays of shape (X, Y, Z) into tensor type and single-precision floating point type.\n    Changes the shape of one of them to (X, Z, Y).\n    Calculates the attention scores of these two matrices and outputs the results.\n    Then writes the results into a file named result.txt.\n    \"\"\"\n    tensor1 = torch.tensor(array1, dtype=torch.float32)\n    tensor2 = torch.tensor(array2, dtype=torch.float32)\n    tensor2 = tensor2.permute(0, 2, 1)\n    \n    attention_scores = torch.matmul(tensor1, tensor2)\n    \n    with open(\"result.txt\", \"w\") as f:\n        for i in range(attention_scores.shape[0]):\n            for j in range(attention_scores.shape[1]):\n                for k in range(attention_scores.shape[2]):\n                    f.write(str(attention_scores[i, j, k].item()) + \"\\n\")\n                    \n    return attention_scores", "correct_code": "import torch\nimport numpy as np\n\n\ndef process_tensor(array1, array2):\n    tensor1 = torch.FloatTensor(array1)\n    tensor2 = torch.FloatTensor(array2)\n    tensor2 = tensor2.permute(0, 2, 1)\n    attention_scores = torch.bmm(tensor1, tensor2)\n    with open('result.txt', 'w') as file:\n        file.write(str(attention_scores))\n    return attention_scores\n\n\narray1 = np.ones((100, 130, 80))\narray2 = np.ones((100, 130, 80))\nprint(process_tensor(array1, array2).shape)", "test_code": "import torch\n\nclass Testprocess_tensor:\n    def test_process_tensor_2(self):\n        array1 = np.zeros((3, 9, 5))\n        array2 = np.ones((3, 9, 5))\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.zeros((3, 9, 9))))\n\n    def test_process_tensor_3(self):\n        array1 = np.ones((3, 9, 5))*2\n        array2 = np.ones((3, 9, 5))*3\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((3, 9, 9))*30))\n\n    def test_process_tensor_4(self):\n        array1 = np.ones((3, 9, 5))*-1\n        array2 = np.ones((3, 9, 5))*-1\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((3, 9, 9))*5))\n\n    def test_process_tensor_5(self):\n        array1 = np.ones((3, 9, 5))*-1\n        array2 = np.ones((3, 9, 5))\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((3, 9, 9))*-5))\n\n    # boundary cases\n    def test_process_tensor_6(self):\n        array1 = np.ones((1, 1, 1))\n        array2 = np.ones((1, 1, 1))\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((1, 1, 1))))\n\n    def test_process_tensor_7(self):\n        array1 = np.ones((100, 130, 80))\n        array2 = np.ones((100, 130, 80))\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((100, 130, 130))*80))\n\n    def test_process_tensor_8(self):\n        array1 = np.ones((2, 2, 2))*np.inf\n        array2 = np.ones((2, 2, 2))\n        assert torch.all(torch.eq(process_tensor(array1, array2), torch.ones((2, 2, 2))*np.inf))\n\n    def test_process_tensor_9(self):\n        array1 = np.ones((2, 2, 2))*np.nan\n        array2 = np.ones((2, 2, 2))\n        assert torch.all(torch.isnan(process_tensor(array1, array2)))", "required_packages": ["numpy", "torch"]}
{"id": "28", "title": "Implementing Distance and Similarity Metrics", "description": "Implement functions to calculate various distance and similarity metrics between data points.  These include Euclidean distance, Manhattan distance, Chebyshev distance, Minkowski distance, Cosine similarity, Hamming distance, and Jaccard similarity.", "language": "python", "difficulty": "medium", "category": "Algorithm and Data Structure", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite Euclidean, Manhattan, Chebyshev, Minkowski, Cosine similarity, Hamming distance, Jaccard similarity and other distance calculation methods in Python functions. Manually write data to call these distance calculation functions. Output the calculation results.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testeuclidean_distance:\n    def test_euclidean_distance_1(self):\n        assert euclidean_distance((1, 2, 3), (4, 5, 6)) == 5.196152422706632\n        assert manhattan_distance((1, 2, 3), (4, 5, 6)) == 9\n        assert chebyshev_distance((1, 2, 3), (4, 5, 6)) == 3\n        assert minkowski_distance((1, 2, 3), (4, 5, 6), 2) == 6.244997998398398\n        assert cosine_similarity([1, 2, 3], [4, 5, 6]) == 0.9746318461970762\n        assert hamming_distance(\"1010101\", \"1001001\") == 3\n        assert jaccard_similarity({1, 2, 3, 4, 5}, {4, 5, 6, 7, 8}) == 0.25\n\n", "llm_code": "import math\n\ndef euclidean_distance(point1, point2):\n    \"\"\"Calculates the Euclidean distance between two points.\"\"\"\n    distance = 0\n    for i in range(len(point1)):\n        distance += (point1[i] - point2[i]) ** 2\n    return math.sqrt(distance)\n\ndef manhattan_distance(point1, point2):\n    \"\"\"Calculates the Manhattan distance between two points.\"\"\"\n    distance = 0\n    for i in range(len(point1)):\n        distance += abs(point1[i] - point2[i])\n    return distance\n\ndef chebyshev_distance(point1, point2):\n    \"\"\"Calculates the Chebyshev distance between two points.\"\"\"\n    distance = 0\n    for i in range(len(point1)):\n        distance = max(distance, abs(point1[i] - point2[i]))\n    return distance\n\ndef minkowski_distance(point1, point2, p):\n    \"\"\"Calculates the Minkowski distance between two points.\"\"\"\n    distance = 0\n    for i in range(len(point1)):\n        distance += abs(point1[i] - point2[i]) ** p\n    return distance ** (1 / p)\n\ndef cosine_similarity(vector1, vector2):\n    \"\"\"Calculates the cosine similarity between two vectors.\"\"\"\n    dot_product = 0\n    magnitude1 = 0\n    magnitude2 = 0\n    for i in range(len(vector1)):\n        dot_product += vector1[i] * vector2[i]\n        magnitude1 += vector1[i] ** 2\n        magnitude2 += vector2[i] ** 2\n    return dot_product / (math.sqrt(magnitude1) * math.sqrt(magnitude2))\n\ndef hamming_distance(string1, string2):\n    \"\"\"Calculates the Hamming distance between two strings.\"\"\"\n    distance = 0\n    for i in range(len(string1)):\n        if string1[i] != string2[i]:\n            distance += 1\n    return distance\n\ndef jaccard_similarity(set1, set2):\n    \"\"\"Calculates the Jaccard similarity between two sets.\"\"\"\n    intersection = len(set1.intersection(set2))\n    union = len(set1.union(set2))\n    return intersection / union", "correct_code": "import math\n\ndef euclidean_distance(point1, point2):\n    return math.sqrt(sum((p - q) ** 2 for p, q in zip(point1, point2)))\n\ndef manhattan_distance(point1, point2):\n    return sum(abs(p - q) for p, q in zip(point1, point2))\n\ndef chebyshev_distance(point1, point2):\n    return max(abs(p - q) for p, q in zip(point1, point2))\n\ndef minkowski_distance(point1, point2, p):\n    return math.pow(sum(abs(p - q) ** p for p, q in zip(point1, point2)), 1/p)\n\ndef cosine_similarity(vector1, vector2):\n    dot_product = sum(p * q for p, q in zip(vector1, vector2))\n    norm_vector1 = math.sqrt(sum(p ** 2 for p in vector1))\n    norm_vector2 = math.sqrt(sum(q ** 2 for q in vector2))\n    return dot_product / (norm_vector1 * norm_vector2)\n\n\ndef hamming_distance(string1, string2):\n    return sum(p != q for p, q in zip(string1, string2))\n\ndef jaccard_similarity(set1, set2):\n    intersection_size = len(set1.intersection(set2))\n    union_size = len(set1.union(set2))\n    return intersection_size / union_size", "test_code": "\n\nclass Testeuclidean_distance:\n    def test_euclidean_distance_2(self):\n        assert euclidean_distance((0, 0), (0, 0)) == 0\n        assert manhattan_distance((0, 0), (0, 0)) == 0\n        assert chebyshev_distance((0, 0), (0, 0)) == 0\n        assert minkowski_distance((0, 0), (0, 0), 2) == 1.4142135623730951\n        assert cosine_similarity([0, 1], [0, 1]) == 1\n        assert hamming_distance(\"0000000\", \"0000000\") == 0\n        assert jaccard_similarity({1, 2, 3}, {4, 5, 6}) == 0\n\n    def test_euclidean_distance_3(self):\n        assert euclidean_distance((1, 1), (-1, -1)) == 2.8284271247461903\n        assert manhattan_distance((1, 1), (-1, -1)) == 4\n        assert chebyshev_distance((1, 1), (-1, -1)) == 2\n        assert minkowski_distance((1, 1), (-1, -1), 2) == 2.0\n        assert cosine_similarity([1, 1], [-1, -1]) == -0.9999999999999998\n        assert hamming_distance(\"1111111\", \"0000000\") == 7\n        assert jaccard_similarity({1, 2, 3}, {1, 2, 3}) == 1\n\n    def test_euclidean_distance_4(self):\n        assert euclidean_distance((1, 2, 3, 4), (5, 6, 7, 8)) == 8.0\n        assert manhattan_distance((1, 2, 3, 4), (5, 6, 7, 8)) == 16\n        assert chebyshev_distance((1, 2, 3, 4), (5, 6, 7, 8)) == 4\n        assert minkowski_distance((1, 2, 3, 4), (5, 6, 7, 8), 2) == 18.439088914585774\n        assert cosine_similarity([1, 2, 3, 4], [5, 6, 7, 8]) == 0.9688639316269662\n        assert hamming_distance(\"1010101\", \"0101010\") == 7\n        assert jaccard_similarity({1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}) == 0\n\n    def test_euclidean_distance_5(self):\n        assert euclidean_distance((1, 1, 1, 1), (2, 2, 2, 2)) == 2.0\n        assert manhattan_distance((1, 1, 1, 1), (2, 2, 2, 2)) == 4\n        assert chebyshev_distance((1, 1, 1, 1), (2, 2, 2, 2)) == 1\n        assert minkowski_distance((1, 1, 1, 1), (2, 2, 2, 2), 2) == 2.0\n        assert cosine_similarity([1] * 100, [100] * 100) == 1.0\n        assert hamming_distance(\"1101001\", \"1010110\") == 6\n        assert jaccard_similarity({143, 2, 1234, 4, 5, 23}, {422, 5, 346, 7343, 1234123, 1}) == 0.09090909090909091\n\n    def test_euclidean_distance_6(self):\n        assert euclidean_distance((1, 2, 3, 4, 5), (6, 7, 8, 9, 10)) == 11.180339887498949\n        assert manhattan_distance((1, 2, 3, 4, 5), (6, 7, 8, 9, 10)) == 25\n        assert chebyshev_distance((1, 2, 3, 4, 5), (6, 7, 8, 9, 10)) == 5\n        assert minkowski_distance((1, 2, 3, 4, 5), (6, 7, 8, 9, 10), 2) == 62.489999199871974\n        assert cosine_similarity([1] * 100 + [2] * 100 + [3] * 100, [100] * 300) == 0.9258200997725514\n        assert hamming_distance(\"1100110\", \"0011001\") == 7\n        assert jaccard_similarity({143, 2, 1234, 4, 5, 23, 123}, {1, 2, 3, 4, 5, 6, 7}) == 0.2727272727272727\n", "required_packages": ["math"]}
{"id": "29", "title": "Flatten Array After Thresholding", "description": "", "language": "python", "difficulty": "easy", "category": "Algorithm and Data Structure", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nAssume there is a numpy array of size=[N, N]. Calculate the average of the array elements, then keep the elements that are greater than the average unchanged, set the elements that are less than the average to 1, flatten the array into a one-dimensional list, and output the result.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testarray_avg:\n    def test_array_avg_1(self):\n        matrix = np.array([[2,1,4,3],[4,5,8,9],[10,2,3,4],[1,14,21,2]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 5.8125\n        assert np.all(flattened_array == np.array([2, 1, 4, 3, 4, 5, 0, 0, 0, 2, 3, 4, 1, 0, 0, 2]))\n\n", "llm_code": "import numpy as np\n\ndef array_avg(matrix):\n    mean_value = np.mean(matrix)\n    new_matrix = np.where(matrix > mean_value, matrix, 1)\n    flattened_array = new_matrix.flatten()\n    return mean_value, flattened_array", "correct_code": "import numpy as np\n\n\ndef array_avg(matrix):\n    # \u8ba1\u7b97\u6570\u7ec4\u5143\u7d20\u7684\u5e73\u5747\u503c\n    mean_value = np.mean(matrix)\n\n    # \u5927\u4e8e\u5e73\u5747\u503c\u7684\u5143\u7d20\u7f6e\u4e3a\u96f6\n    matrix[matrix > mean_value] = 0\n\n    # \u5c06\u6570\u7ec4\u5c55\u5f00\u4e3a\u4e00\u7ef4\u5217\u8868\n    flattened_array = matrix.flatten()\n    return mean_value, flattened_array\n\nmatrix = [[2,1,4,3],[4,5,8,9],[10,2,3,4],[1,14,21,2]]\nmatrix = np.array(matrix)\nprint(array_avg(matrix))", "test_code": "\n\nclass Testarray_avg:\n    def test_array_avg_2(self):\n        matrix = np.array([[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 1\n        assert np.all(flattened_array == np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]))\n\n    def test_array_avg_3(self):\n        matrix = np.array([[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 0\n        assert np.all(flattened_array == np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]))\n\n    def test_array_avg_4(self):\n        matrix = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 8.5\n        assert np.all(flattened_array == np.array([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0]))\n\n    def test_array_avg_5(self):\n        matrix = np.array([[10,20,30,40],[50,60,70,80],[90,100,110,120],[130,140,150,160]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 85\n        assert np.all(flattened_array == np.array([10, 20, 30, 40, 50, 60, 70, 80,  0,  0,  0,  0,  0,  0,  0,  0]))\n\n    def test_array_avg_6(self):\n        matrix = np.array([[1,2,3,4],[4,3,2,1],[1,2,3,4],[4,3,2,1]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 2.5\n        assert np.all(flattened_array == np.array([1, 2, 0, 0, 0, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 1]))\n\n    def test_array_avg_7(self):\n        matrix = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 2.5\n        assert np.all(flattened_array == np.array([1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]))\n\n    def test_array_avg_8(self):\n        matrix = np.array([[1,1,1,1],[1,1,1,1],[1,1,1,1],[100,100,100,100]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 25.75\n        assert np.all(flattened_array == np.array([1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0]))\n\n    def test_array_avg_9(self):\n        matrix = np.array([[1,1,1,1],[1,1,1,1],[1,1,1,1],[1000,1000,1000,1000]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 250.75\n        assert np.all(flattened_array == np.array([1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0]))\n\n    def test_array_avg_10(self):\n        matrix = np.array([[1,1,1,1],[1,1,1,1],[1,1,1,1],[10000,10000,10000,10000]])\n        mean_value, flattened_array = array_avg(matrix)\n        assert mean_value == 2500.75\n        assert np.all(flattened_array == np.array([1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0]))", "required_packages": ["numpy"]}
{"id": "3", "title": "Valid String Sequence", "description": "Given a string `s` containing only lowercase letters, determine if it meets specific criteria.  The string's length must be between 2 and 10 (inclusive).  It must not contain consecutive repeating characters.  The string can be divided into two parts (left and right) such that either both parts are palindromes or both parts are increasing sequences (characters' ASCII values strictly increase).  Return `True` if all conditions are met, and `False` otherwise.", "language": "python", "difficulty": "medium", "category": "Algorithm and Data Structure", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program, the content of the program is to give a string s that only contains lowercase letters, please write a function is_valid_sequence(s), to determine whether the string meets the following conditions:\nThe length of the string s is between 2 and 10 (including 2 and 10).\nEach character in the string s must be a lowercase letter.\nThere can be no consecutive repeated characters in the string s, that is, adjacent characters cannot be the same.\nIf the string s is divided into left and right parts, the left and right parts must meet one of the following conditions:\nBoth the left and right parts are palindrome strings.\nBoth the left and right parts are increasing sequences (that is, the ASCII value of each character is greater than the previous character). The is_valid_sequence function accepts a string s as a parameter.\n\nFirst, check whether the length of the string is between 2 and 10, if it is not in this range, return False.\n\nThen, check whether all the characters in the string are lowercase letters, if there are characters that are not lowercase letters, return False.\n\nNext, check whether there are consecutive repeated characters in the string, if there are, return False.\n\nFinally, determine whether the string can be divided into left and right parts, and these two parts are either palindrome strings or increasing sequences. If this condition is met, return True; otherwise, return False.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testis_valid_sequence:\n    def test_is_valid_sequence_case1(self):\n        assert is_valid_sequence(\"abba\") == False\n\n", "llm_code": "def is_valid_sequence(s):\n    \"\"\"\n    Determines whether the string meets the specified conditions.\n\n    Args:\n        s: The string to check.\n\n    Returns:\n        True if the string is valid, False otherwise.\n    \"\"\"\n\n    # Check the length of the string.\n    if not 2 <= len(s) <= 10:\n        return False\n\n    # Check if all characters are lowercase letters.\n    if not all('a' <= char <= 'z' for char in s):\n        return False\n\n    # Check for consecutive repeated characters.\n    for i in range(len(s) - 1):\n        if s[i] == s[i + 1]:\n            return False\n\n    # Check if the string can be divided into left and right parts that are either palindromes or increasing sequences.\n    for i in range(1, len(s)):\n        left = s[:i]\n        right = s[i:]\n\n        def is_palindrome(sub):\n            return sub == sub[::-1]\n\n        def is_increasing(sub):\n            for j in range(len(sub) - 1):\n                if ord(sub[j]) >= ord(sub[j + 1]):\n                    return False\n            return True\n\n        if (is_palindrome(left) and is_palindrome(right)) or \\\n           (is_increasing(left) and is_increasing(right)):\n            return True\n\n    return False", "correct_code": "def is_valid_sequence(s):\n    # \u5224\u65ad\u5b57\u7b26\u4e32\u957f\u5ea6\u662f\u5426\u5728 2 \u5230 10 \u4e4b\u95f4\n    if len(s) < 2 or len(s) > 10:\n        return False\n\n        # \u5224\u65ad\u5b57\u7b26\u4e32\u4e2d\u7684\u5b57\u7b26\u662f\u5426\u90fd\u662f\u5c0f\u5199\u5b57\u6bcd\n    for char in s:\n        if not char.islower():\n            return False\n\n            # \u5224\u65ad\u5b57\u7b26\u4e32\u4e2d\u662f\u5426\u51fa\u73b0\u8fde\u7eed\u7684\u91cd\u590d\u5b57\u7b26\n    for i in range(len(s) - 1):\n        if s[i] == s[i + 1]:\n            return False\n\n            # \u5224\u65ad\u5de6\u53f3\u4e24\u90e8\u5206\u662f\u5426\u90fd\u662f\u56de\u6587\u5b57\u7b26\u4e32\u6216\u9012\u589e\u5e8f\u5217\n    left, right = s[:len(s) // 2], s[len(s) // 2:]\n    if left == right[::-1] or sorted(left) == sorted(right):\n        return True\n    else:\n        return False", "test_code": "\nclass Testis_valid_sequence:\n    def test_is_valid_sequence_case2(self):\n        assert is_valid_sequence(\"abcd\") == False\n\n    def test_is_valid_sequence_case3(self):\n        assert is_valid_sequence(\"a\") == False\n\n    def test_is_valid_sequence_case4(self):\n        assert is_valid_sequence(\"abcdefghij\") == False\n\n    def test_is_valid_sequence_case5(self):\n        assert is_valid_sequence(\"Abba\") == False\n\n    def test_is_valid_sequence_case6(self):\n        assert is_valid_sequence(\"abbb\") == False\n\n    def test_is_valid_sequence_case7(self):\n        assert is_valid_sequence(\"abcde\") == False\n\n    def test_is_valid_sequence_case8(self):\n        assert is_valid_sequence(\"\") == False", "required_packages": []}
{"id": "30", "title": "Automated Time-Stamped Backup with Size Limit", "description": "Design a Python backup program that takes a source and target directory path as input.  The program should create timestamped compressed backups of the source directory's contents in the target directory. Backups should be compressed using zip.  The program must also manage the total size of the backup directory. If the total size exceeds a given threshold (in MB), the program should automatically delete the oldest backup files until the total size is below the threshold.", "language": "python", "difficulty": "medium", "category": "Operation System", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nDesign a backup program, which should be written in Python. The program input is the source path and the target path. It should complete the backup of the contents under the specified folder (for example, the data folder). Each backup should include a timestamp, and the backup files should be compressed. The compressed backup files should be stored in another specified folder (for example, the backup folder). There may already be some backup files in the backup folder. When the total size of the backup folder exceeds a threshold (MB), the program should automatically delete the oldest backup files to free up space.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testbackup:\n    def test_backup_1(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 1\n\n", "llm_code": "import os\nimport shutil\nimport zipfile\nimport time\nimport datetime\n\ndef get_dir_size(path):\n    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            total_size += os.path.getsize(fp)\n    return total_size\n\ndef delete_oldest_backup(backup_folder, threshold_mb):\n    threshold_bytes = threshold_mb * 1024 * 1024\n    total_size = get_dir_size(backup_folder)\n    if total_size > threshold_bytes:\n        files = sorted([os.path.join(backup_folder, f) for f in os.listdir(backup_folder) if f.endswith(\".zip\")], key=os.path.getmtime)\n        while total_size > threshold_bytes and files:\n            oldest_file = files.pop(0)\n            file_size = os.path.getsize(oldest_file)\n            os.remove(oldest_file)\n            total_size -= file_size\n            print(f\"Deleted oldest backup: {oldest_file}\")\n\ndef backup(source_path, backup_folder, threshold_mb=100):  # threshold_mb = 100MB by default\n    \"\"\"\n    Backs up the contents of the source path to the backup folder,\n    including a timestamp in the backup filename, compressing the backup,\n    and deleting the oldest backups if the backup folder exceeds the threshold.\n    \"\"\"\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n    backup_filename = f\"backup_{timestamp}.zip\"\n    backup_filepath = os.path.join(backup_folder, backup_filename)\n\n    with zipfile.ZipFile(backup_filepath, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(source_path):\n            for file in files:\n                filepath = os.path.join(root, file)\n                zipf.write(filepath, os.path.relpath(filepath, source_path))\n\n    delete_oldest_backup(backup_folder, threshold_mb)", "correct_code": "import os\nimport shutil\nimport zipfile\nfrom datetime import datetime\nimport glob\n\ndef backup(source_path, backup_folder, max_size_mb=10):\n    # \u521b\u5efa\u5907\u4efd\u6587\u4ef6\u5939\n    if not os.path.exists(backup_folder):\n        os.makedirs(backup_folder)\n\n    # \u751f\u6210\u65f6\u95f4\u6233\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n\n    # \u6784\u5efa\u5907\u4efd\u6587\u4ef6\u540d\n    backup_filename = f\"backup_{timestamp}.zip\"\n    backup_path = os.path.join(backup_folder, backup_filename)\n\n    # \u5907\u4efd\u6587\u4ef6\u5939\n    shutil.make_archive(backup_path[:-4], 'zip', source_path)\n\n    # \u83b7\u53d6\u5907\u4efd\u6587\u4ef6\u5939\u603b\u5927\u5c0f\n    total_size_mb = sum(os.path.getsize(f) for f in glob.glob(os.path.join(backup_folder, '*.zip'))) / (1024 ** 2)\n\n    # \u5982\u679c\u603b\u5927\u5c0f\u8d85\u8fc7\u8bbe\u5b9a\u7684\u9608\u503c\uff0c\u5220\u9664\u6700\u65e7\u7684\u5907\u4efd\u6587\u4ef6\n    while total_size_mb > max_size_mb:\n        oldest_backup = min(glob.glob(os.path.join(backup_folder, '*.zip')), key=os.path.getctime)\n        total_size_mb -= os.path.getsize(oldest_backup) / (1024 ** 2)\n        os.remove(oldest_backup)\n\n    print(f\"Backup completed: {backup_path}\")", "test_code": "import os\nimport shutil\nimport zipfile\nfrom datetime import datetime\nimport time\n\n\nclass Testbackup:\n    def test_backup_2(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.00001)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 0\n\n    def test_backup_3(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 1\n\n    def test_backup_4(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 2\n\n    def test_backup_5(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.00001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.02)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 1\n\n    def test_backup_6(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 3\n\n    def test_backup_7(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 4\n\n    def test_backup_8(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 0\n\n    def test_backup_9(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.01)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 6\n\n    def test_backup_10(self, tmp_path):\n        source_path = tmp_path / \"source\"\n        backup_folder = tmp_path / \"backup\"\n        source_path.mkdir()\n        backup_folder.mkdir()\n        (source_path / \"file1.txt\").write_text(\"Hello, World!\")\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        time.sleep(1)\n        backup(source_path, backup_folder, max_size_mb=0.000001)\n        assert len(list(backup_folder.glob(\"*.zip\"))) == 0\n", "required_packages": ["shutil", "zipfile", "glob", "os", "datetime", "time"]}
{"id": "31", "title": "Bounding Box IOU Calculation", "description": "Given two sets of bounding boxes, calculate the Intersection over Union (IoU) for each corresponding pair of boxes.", "language": "python", "difficulty": "easy", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nPlease use Python language and PyTorch package to calculate the IOU of two sets of bounding boxes.\n\nEach set of bounding boxes has dimensions of [N, 4], representing N bounding boxes, and 4 represents [x, y, w, h].\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testbbox_iou:\n    def test_bbox_iou_1(self):\n        boxes1 = torch.tensor([[10, 20, 30, 40], [30, 40, 50, 60]])\n        boxes2 = torch.tensor([[15, 25, 35, 45], [40, 50, 60, 70]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.5914, 0.5238]), atol=1e-4)\n\n", "llm_code": "import torch\n\ndef bbox_iou(boxes1, boxes2):\n    \"\"\"\n    Calculates the Intersection over Union (IoU) of two sets of bounding boxes.\n\n    Args:\n        boxes1 (torch.Tensor): Tensor of shape [N, 4] representing N bounding boxes in the format [x, y, w, h].\n        boxes2 (torch.Tensor): Tensor of shape [N, 4] representing N bounding boxes in the format [x, y, w, h].\n\n    Returns:\n        torch.Tensor: Tensor of shape [N] containing the IoU values for each pair of bounding boxes.\n    \"\"\"\n\n    x1 = boxes1[:, 0]\n    y1 = boxes1[:, 1]\n    w1 = boxes1[:, 2]\n    h1 = boxes1[:, 3]\n\n    x2 = boxes2[:, 0]\n    y2 = boxes2[:, 1]\n    w2 = boxes2[:, 2]\n    h2 = boxes2[:, 3]\n\n    # Calculate coordinates of top-left and bottom-right corners for each box\n    x1_min = x1\n    y1_min = y1\n    x1_max = x1 + w1\n    y1_max = y1 + h1\n\n    x2_min = x2\n    y2_min = y2\n    x2_max = x2 + w2\n    y2_max = y2 + h2\n\n    # Calculate coordinates of intersection rectangle\n    x_intersect_min = torch.max(x1_min, x2_min)\n    y_intersect_min = torch.max(y1_min, y2_min)\n    x_intersect_max = torch.min(x1_max, x2_max)\n    y_intersect_max = torch.min(y1_max, y2_max)\n\n    # Calculate area of intersection rectangle\n    intersect_width = torch.clamp(x_intersect_max - x_intersect_min, min=0)\n    intersect_height = torch.clamp(y_intersect_max - y_intersect_min, min=0)\n    intersect_area = intersect_width * intersect_height\n\n    # Calculate area of each bounding box\n    area1 = w1 * h1\n    area2 = w2 * h2\n\n    # Calculate union area\n    union_area = area1 + area2 - intersect_area\n\n    # Calculate IoU\n    iou = intersect_area / union_area\n\n    return iou", "correct_code": "import torch\n\ndef bbox_iou(boxes1, boxes2):\n    \"\"\"\n    \u8ba1\u7b97\u4e24\u7ec4\u5bf9\u5e94\u4f4d\u7f6ebounding boxes\u7684IoU\u3002\n    \n    \u53c2\u6570:\n    boxes1, boxes2: \u7ef4\u5ea6\u4e3a[N, 4]\u7684tensor\uff0c\u8868\u793abounding boxes\uff0c\u683c\u5f0f\u4e3a[x, y, w, h]\u3002\n    \n    \u8fd4\u56de:\n    \u4e00\u4e2a\u957f\u5ea6\u4e3aN\u7684tensor\uff0c\u8868\u793aboxes1\u548cboxes2\u4e2d\u5bf9\u5e94box\u7684IoU\u3002\n    \"\"\"\n    assert boxes1.shape == boxes2.shape\n    boxes1_x1 = boxes1[:, 0] - boxes1[:, 2] / 2\n    boxes1_y1 = boxes1[:, 1] - boxes1[:, 3] / 2\n    boxes1_x2 = boxes1[:, 0] + boxes1[:, 2] / 2\n    boxes1_y2 = boxes1[:, 1] + boxes1[:, 3] / 2\n\n    boxes2_x1 = boxes2[:, 0] - boxes2[:, 2] / 2\n    boxes2_y1 = boxes2[:, 1] - boxes2[:, 3] / 2\n    boxes2_x2 = boxes2[:, 0] + boxes2[:, 2] / 2\n    boxes2_y2 = boxes2[:, 1] + boxes2[:, 3] / 2\n\n\n    inter_x1 = torch.max(boxes1_x1, boxes2_x1)\n    inter_y1 = torch.max(boxes1_y1, boxes2_y1)\n    inter_x2 = torch.min(boxes1_x2, boxes2_x2)\n    inter_y2 = torch.min(boxes1_y2, boxes2_y2)\n\n    inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)\n\n\n    boxes1_area = (boxes1_x2 - boxes1_x1) * (boxes1_y2 - boxes1_y1)\n    boxes2_area = (boxes2_x2 - boxes2_x1) * (boxes2_y2 - boxes2_y1)\n\n\n    union_area = boxes1_area + boxes2_area - inter_area\n\n\n    iou = inter_area / union_area\n\n    return iou", "test_code": "import torch\n\n\nclass Testbbox_iou:\n    def test_bbox_iou_2(self):\n        boxes1 = torch.tensor([[0, 0, 10, 10]])\n        boxes2 = torch.tensor([[0, 0, 10, 10]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([1.0]), atol=1e-4)\n\n    def test_bbox_iou_3(self):\n        boxes1 = torch.tensor([[0, 0, 10, 10]])\n        boxes2 = torch.tensor([[10, 10, 10, 10]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.0]), atol=1e-4)\n\n    def test_bbox_iou_4(self):\n        boxes1 = torch.tensor([[0, 0, 10, 10]])\n        boxes2 = torch.tensor([[5, 5, 10, 10]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.1429]), atol=1e-4)\n\n    def test_bbox_iou_5(self):\n        boxes1 = torch.tensor([[0, 0, 10, 10]])\n        boxes2 = torch.tensor([[5, 5, 5, 5]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.0526]), atol=1e-4)\n\n    def test_bbox_iou_6(self):\n        boxes1 = torch.tensor([[0, 0, 10, 10]])\n        boxes2 = torch.tensor([[5, 5, 15, 15]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.2093]), atol=1e-4)\n\n    def test_bbox_iou_7(self):\n        boxes1 = torch.tensor([[0, 0, 0, 0]])\n        boxes2 = torch.tensor([[0, 0, 0, 0]])\n        assert torch.isnan(bbox_iou(boxes1, boxes2))\n\n    def test_bbox_iou_8(self):\n        boxes1 = torch.tensor([[0, 0, 100, 100]])\n        boxes2 = torch.tensor([[0, 0, 100, 100]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([1.0]), atol=1e-4)\n\n    def test_bbox_iou_9(self):\n        boxes1 = torch.tensor([[0, 0, 100, 100]])\n        boxes2 = torch.tensor([[100, 100, 100, 100]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.0]), atol=1e-4)\n\n    def test_bbox_iou_10(self):\n        boxes1 = torch.tensor([[0, 0, 100, 100]])\n        boxes2 = torch.tensor([[50, 50, 100, 100]])\n        assert torch.allclose(bbox_iou(boxes1, boxes2), torch.tensor([0.1429]), atol=1e-4)", "required_packages": ["torch"]}
{"id": "32", "title": "K-means Clustering with Scikit-learn", "description": "Implement K-means clustering using scikit-learn on a manually created dataset.  You will use a fixed random seed (42) for reproducibility. The function should take the data and the desired number of clusters as input.  Your task is to return an array containing the cluster label assigned to each data point after performing K-means.  The `n_init` parameter should be explicitly set to 10 within the KMeans constructor.", "language": "python", "difficulty": "easy", "category": "Artificial Intelligence", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nManually write data to demonstrate the use of the K-means clustering algorithm in the scikit-learn library (sklearn). The random seed is 42. Calculate the output results of each data sample.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testk_means_clustering:\n    def test_k_means_clustering_1(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [5, 8], [1.5, 1.8], [8, 8], [1, 0.6], [9, 11]])\n        num_clusters = 2\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([1, 0, 1, 0, 1, 0]))\n\n", "llm_code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\ndef k_means_clustering(data, num_clusters):\n    \"\"\"\n    Performs K-means clustering on the given data.\n\n    Args:\n        data (np.ndarray): The input data array.\n        num_clusters (int): The number of clusters to form.\n\n    Returns:\n        np.ndarray: The cluster labels for each data sample.\n    \"\"\"\n    np.random.seed(42)\n    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)  # Explicitly set n_init\n    kmeans.fit(data)\n    return kmeans.labels_", "correct_code": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef k_means_clustering(data, num_clusters):\n    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n    kmeans.fit(data)\n    return kmeans.labels_", "test_code": "from sklearn.cluster import KMeans\nimport numpy as np\n\n\nclass Testk_means_clustering:\n    def test_k_means_clustering_2(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [5, 8], [1.5, 1.8], [8, 8], [1, 0.6], [9, 11]])\n        num_clusters = 3\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([0, 1, 0, 1, 0, 2]))\n\n    def test_k_means_clustering_3(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [5, 8], [1.5, 1.8], [8, 8], [1, 0.6], [9, 11]])\n        num_clusters = 1\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([0, 0, 0, 0, 0, 0]))\n\n    def test_k_means_clustering_4(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [5, 8], [1.5, 1.8], [8, 8], [1, 0.6], [9, 11]])\n        num_clusters = 6\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([5, 2, 1, 0, 4, 3]))\n\n    def test_k_means_clustering_5(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2]])\n        num_clusters = 2\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([0, 0, 0, 0, 0, 0]))\n\n    def test_k_means_clustering_6(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n        num_clusters = 2\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([1, 1, 1, 0, 0, 0]))\n\n    def test_k_means_clustering_7(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2]])\n        num_clusters = 1\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([0, 0, 0, 0, 0, 0]))\n\n    def test_k_means_clustering_8(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2]])\n        num_clusters = 6\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([0, 0, 0, 0, 0, 0]))\n\n    def test_k_means_clustering_9(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n        num_clusters = 1\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([0, 0, 0, 0, 0, 0]))\n\n    def test_k_means_clustering_10(self):\n        np.random.seed(0)\n        data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n        num_clusters = 6\n        assert np.all(k_means_clustering(data, num_clusters) == np.array([4, 1, 2, 0, 5, 3]))", "required_packages": ["numpy", "sklearn"]}
{"id": "33", "title": "Gamma Image Correction", "description": "Given an image represented as a NumPy array and a gamma value (float), implement a function `gamma_correction(image, gamma)` that applies gamma correction to the image.", "language": "python", "difficulty": "easy", "category": "Software Engineering", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nComplete gamma brightness correction for images using Python.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testgamma_correction:\n    def test_gamma_correction_1(self):\n        image = cv2.imread('test1/test.jpg', cv2.IMREAD_COLOR)\n        gamma = 1.5\n        corrected_image = gamma_correction(image, gamma)\n        label = cv2.imread('test1/label.png', cv2.IMREAD_COLOR)\n        assert (corrected_image == label).all()\n\n", "llm_code": "import cv2\nimport numpy as np\n\ndef gamma_correction(image, gamma):\n    \"\"\"\n    Applies gamma correction to an image.\n\n    Args:\n        image (numpy.ndarray): The input image.\n        gamma (float): The gamma value.\n\n    Returns:\n        numpy.ndarray: The gamma corrected image.\n    \"\"\"\n    # Normalize the image to the range [0, 1]\n    image_normalized = image / 255.0\n\n    # Apply gamma correction\n    corrected_image_normalized = np.power(image_normalized, gamma)\n\n    # Scale back to the range [0, 255] and convert to uint8\n    corrected_image = np.uint8(corrected_image_normalized * 255)\n\n    return corrected_image", "correct_code": "import cv2\nimport numpy as np\n\ndef gamma_correction(image, gamma):\n    # \u5c06\u56fe\u50cf\u7684\u4eae\u5ea6\u503c\u8f6c\u6362\u4e3a\u8303\u56f4\u5728[0, 1]\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\n    image = image / 255.0\n    \n    # \u5bf9\u56fe\u50cf\u8fdb\u884c\u4f3d\u9a6c\u4eae\u5ea6\u77eb\u6b63\n    corrected_image = np.power(image, gamma)\n    \n    # \u5c06\u4eae\u5ea6\u503c\u91cd\u65b0\u7f29\u653e\u5230\u8303\u56f4[0, 255]\n    corrected_image = np.uint8(corrected_image * 255)\n    \n    return corrected_image", "test_code": "import cv2\n\nclass Testgamma_correction:\n    def test_gamma_correction_2(self):\n        image = cv2.imread('test2/test.jpg', cv2.IMREAD_COLOR)\n        gamma = 2.0\n        corrected_image = gamma_correction(image, gamma)\n        label = cv2.imread('test2/label.png', cv2.IMREAD_COLOR)\n        assert (corrected_image == label).all()\n\n    def test_gamma_correction_3(self):\n        image = cv2.imread('test3/test.jpg', cv2.IMREAD_COLOR)\n        gamma = 0.5\n        corrected_image = gamma_correction(image, gamma)\n        label = cv2.imread('test3/label.png', cv2.IMREAD_COLOR)\n        assert (corrected_image == label).all()\n\n    def test_gamma_correction_4(self):\n        image = cv2.imread('test4/test.jpg', cv2.IMREAD_COLOR)\n        gamma = 0.1\n        corrected_image = gamma_correction(image, gamma)\n        label = cv2.imread('test4/label.png', cv2.IMREAD_COLOR)\n        assert (corrected_image == label).all()\n\n    def test_gamma_correction_5(self):\n        image = cv2.imread('test5/test.jpg', cv2.IMREAD_COLOR)\n        gamma = 10.0\n        corrected_image = gamma_correction(image, gamma)\n        label = cv2.imread('test5/label.png', cv2.IMREAD_COLOR)\n        assert (corrected_image == label).all()\n", "required_packages": ["numpy", "cv2"]}
{"id": "34", "title": "Calculating Evapotranspiration (ET)", "description": "Given meteorological data, calculate the evapotranspiration (ET) using a simplified Penman-Monteith equation.  You will receive the following input parameters:", "language": "python", "difficulty": "medium", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \ndo u remeber i asked questions about calculating ET penman montith with excel and u suggest python would be easier?\n\nso im not good with coding environment can you tell me step by step how can calculate ET with python?\n\nor could you plz write me a code ?\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcalculate_et:\n    def test_calculate_et_1(self):\n        assert np.isclose(calculate_et(0.5, 100, 20, 0.5, 25, 2, 50, 30), 57.25573474907341, atol=1e-5)\n\n", "llm_code": "import numpy as np\n\ndef calculate_et(albedo, solar_radiation, air_temperature, wind_speed, vapor_pressure, psychrometric_constant, latent_heat_of_vaporization, atmospheric_pressure):\n    \"\"\"\n    Calculates evapotranspiration (ET) using a simplified Penman-Monteith equation.\n\n    Args:\n        albedo (float): Albedo (surface reflectivity) [dimensionless].\n        solar_radiation (float): Solar radiation (Rs) [MJ m-2 day-1].\n        air_temperature (float): Air temperature (T) [\u00b0C].\n        wind_speed (float): Wind speed (u) [m/s].\n        vapor_pressure (float): Actual vapor pressure (ea) [kPa].\n        psychrometric_constant (float): Psychrometric constant (\u03b3) [kPa \u00b0C-1].\n        latent_heat_of_vaporization (float): Latent heat of vaporization (\u03bb) [MJ kg-1].\n        atmospheric_pressure (float): Atmospheric pressure (P) [kPa].\n\n    Returns:\n        float: Evapotranspiration (ET) [mm/day].\n    \"\"\"\n\n    # 1. Calculate net radiation (Rn)\n    Rn = (1 - albedo) * solar_radiation\n\n    # 2. Calculate saturation vapor pressure (es)\n    es = 0.6108 * np.exp((17.27 * air_temperature) / (air_temperature + 237.3))\n\n    # 3. Calculate slope of the saturation vapor pressure curve (\u0394)\n    delta = (4098 * es) / ((air_temperature + 237.3)**2)\n\n    # 4. Penman-Monteith equation (simplified)\n    ET = (0.408 * delta * (Rn) + psychrometric_constant * (900 / (air_temperature + 273)) * wind_speed * (es - vapor_pressure)) / (delta + psychrometric_constant * (1 + 0.34 * wind_speed))\n\n\n    return ET", "correct_code": "def calculate_et(delta, rn, g, gamma, t, u2, es, ea):\n    numerator = 0.408 * delta * (rn - g) + gamma * (900 / (t + 273)) * u2 * (es - ea)\n    denominator = delta + gamma * (1 + 0.34 * u2)\n    if denominator == 0:\n        return 0\n    et = numerator / denominator\n\n    print(et)\n    return et", "test_code": "import pytest\nimport numpy as np\n\nclass Testcalculate_et:\n    def test_calculate_et_2(self):\n        assert np.isclose(calculate_et(0.7, 150, 30, 0.6, 30, 3, 60, 40), 73.850780893989, atol=1e-5)\n\n    def test_calculate_et_3(self):\n        assert np.isclose(calculate_et(0.6, 120, 25, 0.7, 28, 2.5, 55, 35), 67.49718353071117, atol=1e-5)\n\n    def test_calculate_et_4(self):\n        assert np.isclose(calculate_et(0.8, 180, 35, 0.8, 32, 3.5, 70, 45), 99.48486561488258, atol=1e-5)\n\n    def test_calculate_et_5(self):\n        assert np.isclose(calculate_et(0.9, 200, 40, 0.9, 35, 4, 80, 50), 123.78849721706865, atol=1e-5)\n\n    def test_calculate_et_6(self):\n        assert np.isclose(calculate_et(1, 220, 45, 1, 38, 4.5, 90, 55), 149.34498055254454, atol=1e-5)\n\n    def test_calculate_et_7(self):\n        assert np.isclose(calculate_et(0, 0, 0, 0, 0, 0, 0, 0), 0, atol=1e-5)\n\n    def test_calculate_et_8(self):\n        assert np.isclose(calculate_et(1, 1, 1, 1, 1, 1, 1, 1), 0, atol=1e-5)\n\n    def test_calculate_et_9(self):\n        assert np.isclose(calculate_et(100, 100, 100, 100, 100, 100, 100, 100), 0, atol=1e-5)\n\n    def test_calculate_et_10(self):\n        assert np.isclose(calculate_et(-1, -1, -1, -1, -1, -1, -1, -1), 0, atol=1e-5)\n\n", "required_packages": ["pytest", "numpy"]}
{"id": "35", "title": "Flatten Nested Dictionary to Pandas Rows", "description": "", "language": "python", "difficulty": "medium", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nHow to flatten the dictionary format in rows of pandas table, with each key-value pair occupying one row? This dictionary might be nested, connect keys at different levels through \".\"\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testflatten_dict_to_rows:\n    def test_flatten_dict_to_rows_1(self):\n        dt = {'A': ['foo', 'bar'], 'B': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}]}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B'}, 'Value': {0: ['foo', 'bar'], 1: [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}]}})\n        pd.testing.assert_frame_equal(result, expected)\n\n", "llm_code": "import pandas as pd\n\ndef flatten_dict_to_rows(dt):\n  \"\"\"\n  Flattens a dictionary into a Pandas DataFrame where each key-value pair\n  occupies one row.\n\n  Args:\n    dt (dict): The dictionary to flatten.\n\n  Returns:\n    pd.DataFrame: A DataFrame with 'Key' and 'Value' columns.\n  \"\"\"\n  keys = list(dt.keys())\n  values = list(dt.values())\n  df = pd.DataFrame({'Key': keys, 'Value': values})\n  return df", "correct_code": "import pandas as pd\n\ndef flatten_dict_to_rows(d):\n    def flatten_dict(d, parent_key='', sep='.'):\n        items = []\n        for k, v in d.items():\n            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n            if isinstance(v, dict):\n                if not v:\n                    items.append((new_key, {}))\n                else:\n                    items.extend(flatten_dict(v, new_key, sep=sep).items())\n            else:\n                items.append((new_key, v))\n        return dict(items)\n\n    flat_dict = flatten_dict(d)\n\n    # Convert the flattened dictionary to a pandas DataFrame\n    df = pd.DataFrame(list(flat_dict.items()), columns=['Key', 'Value'])\n    print(df.to_dict())\n    return df", "test_code": "import pytest\n\nimport pandas as pd\n\nclass Testflatten_dict_to_rows:\n    def test_flatten_dict_to_rows_2(self):\n        dt = {'A': ['foo', 'bar', 'baz'], 'B': {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6}}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B.a', 2: 'B.b', 3: 'B.c', 4: 'B.d', 5: 'B.e', 6: 'B.f'}, 'Value': {0: ['foo', 'bar', 'baz'], 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_3(self):\n        dt = {'A': ['foo'], 'B': {'a': 1, 'b': [2, 3]}}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B.a', 2: 'B.b'}, 'Value': {0: ['foo'], 1: 1, 2: [2, 3]}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_4(self):\n        dt = {'A': {'A.1': 2, 'A.2': {'A.3': 'A.3.1'}}, 'B': {'a': 1}, 'C': {'b': 2}}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A.A.1', 1: 'A.A.2.A.3', 2: 'B.a', 3: 'C.b'}, 'Value': {0: 2, 1: 'A.3.1', 2: 1, 3: 2}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_5(self):\n        dt = {'A': ['foo', 'bar'], 'B': {'a': [1, {'a': 3, 'b': 4}]}}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B.a'}, 'Value': {0: ['foo', 'bar'], 1: [1, {'a': 3, 'b': 4}]}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_6(self):\n        dt = {'A': ['foo', 'bar'], 'B': {\"C\": [{'a': 1, 'b': 2}, {'c': 3, 'd': 4, 'e': 5}]}}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B.C'}, 'Value': {0: ['foo', 'bar'], 1: [{'a': 1, 'b': 2}, {'c': 3, 'd': 4, 'e': 5}]}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_7(self):\n        dt = {'A': [], 'B': []}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B'}, 'Value': {0: [], 1: []}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_8(self):\n        dt = {'A': ['foo'], 'B': [{}]}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'B'}, 'Value': {0: ['foo'], 1: [{}]}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_9(self):\n        dt = {'A': ['foo'], 'C': {}}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {0: 'A', 1: 'C'}, 'Value': {0: ['foo'], 1: {}}})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_flatten_dict_to_rows_10(self):\n        dt = {}\n        result = flatten_dict_to_rows(dt)\n        expected = pd.DataFrame({'Key': {}, 'Value': {}})\n        pd.testing.assert_frame_equal(result, expected, check_dtype=False, check_index_type=False)", "required_packages": ["pytest", "pandas"]}
{"id": "36", "title": "Battery Capacity Estimation", "description": "You are given time-series data representing the voltage discharge curve of a 18650 lithium-ion battery under a constant 1A discharge current.  The data is represented by two arrays: `time_data` (in seconds) and `voltage_data` (in volts). Your task is to estimate the battery's capacity in Amp-hours using a fractional-order model.", "language": "python", "difficulty": "hard", "category": "Software Engineering", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a python code that directly estimates a 18650 lithium-ion battery capacity in Amp hour from a fractional order model with 2 constant phase elements and 3 resistors.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testfractional_order_model:\n    def test_fractional_order_model_1(self):\n        time_data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        current_data = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]))\n        assert round(popt[0], 2) == 0\n\n", "llm_code": "import numpy as np\nfrom scipy.optimize import curve_fit\n\ndef fractional_order_model(t, R0, R1, R2, CPE1_T, CPE1_alpha, CPE2_T, CPE2_alpha, Capacity):\n    \"\"\"\n    Fractional order model with 2 CPEs and 3 resistors for a battery.\n\n    Args:\n        t (array-like): Time data.\n        R0 (float): Ohmic resistance.\n        R1 (float): Resistance of the first RC element.\n        R2 (float): Resistance of the second RC element.\n        CPE1_T (float): Constant Phase Element 1 parameter T.\n        CPE1_alpha (float): Constant Phase Element 1 parameter alpha.\n        CPE2_T (float): Constant Phase Element 2 parameter T.\n        CPE2_alpha (float): Constant Phase Element 2 parameter alpha.\n        Capacity (float): Battery capacity in Amp-hours.\n\n    Returns:\n        array-like: Voltage response of the battery.\n    \"\"\"\n    # This simplified model assumes constant current discharge\n\n    current = 1  #Assume 1A current for calculation.  User needs to scale result\n    voltage = R0 * current  # Immediate voltage drop\n\n    # Approximation of voltage drop over time for RC elements (simplified)\n    voltage += R1 * current * (1 - np.exp(-(t / (R1 * CPE1_T)**(1/CPE1_alpha))))\n    voltage += R2 * current * (1 - np.exp(-(t / (R2 * CPE2_T)**(1/CPE2_alpha))))\n\n    #Voltage drop related to capacity draw\n    voltage += (current * t) / (3600 * Capacity)\n    \n    return voltage\n\n\ndef estimate_capacity(time_data, voltage_data, initial_guess=None, bounds=None):\n    \"\"\"\n    Estimates the capacity of a battery using the fractional order model.\n\n    Args:\n        time_data (array-like): Time data in seconds.\n        voltage_data (array-like): Voltage data.\n        initial_guess (array-like, optional): Initial guess for the parameters\n            [R0, R1, R2, CPE1_T, CPE1_alpha, CPE2_T, CPE2_alpha, Capacity].\n            Defaults to None.\n        bounds (tuple, optional): Bounds for the parameters. Defaults to None.\n\n    Returns:\n        float: Estimated capacity in Amp-hours.\n    \"\"\"\n\n    if initial_guess is None:\n        initial_guess = [0.1, 0.1, 0.1, 0.1, 0.8, 0.1, 0.8, 1.0]  # Initial guess\n\n    if bounds is None:\n        bounds = (0, [1, 1, 1, 1, 1, 1, 1, 10])  # Reasonable bounds\n\n    try:\n        popt, pcov = curve_fit(fractional_order_model, time_data, voltage_data,\n                               p0=initial_guess, bounds=bounds, maxfev=10000)\n        \n        estimated_capacity = popt[-1]\n        return estimated_capacity\n\n    except Exception as e:\n        print(f\"Error during curve fitting: {e}\")\n        return None", "correct_code": "import numpy as np\nfrom scipy.optimize import curve_fit\n\n# Define the fractional order model with 2 constant phase elements and 3 resistors\ndef fractional_order_model(t, Q, R1, R2, R3, n1, n2):\n    return Q * (1 - (1 / (R1 * (t ** n1) + 1)) - (1 / (R2 * (t ** n2) + 1)) - (1 / R3))\n\n# # Sample time and current data\n# time_data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n# current_data = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n#\n# # Fit the model to the data\n# popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]))\n# print(len(popt))\n# # The estimated battery capacity in Amp hour is the first parameter of the model\n# estimated_capacity_Ah = popt[0]\n#\n# print(\"Estimated battery capacity: {:.2f} Ah\".format(estimated_capacity_Ah))", "test_code": "import pytest\n\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\nclass Testfractional_order_model:\n    def test_fractional_order_model_2(self):\n        time_data = np.array([0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n        current_data = np.array([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [2.0, 2.0, 2.0, 2.0, 2.0, 2.0]))\n        assert round(popt[0], 2) == 1.21\n\n    def test_fractional_order_model_3(self):\n        time_data = np.array([0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30])\n        current_data = np.array([0, 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [3.0, 3.0, 3.0, 3.0, 3.0, 3.0]))\n        assert round(popt[0], 2) == 1.95\n\n    def test_fractional_order_model_4(self):\n        time_data = np.array([0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40])\n        current_data = np.array([0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6, 4.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [4.0, 4.0, 4.0, 4.0, 4.0, 4.0]))\n        assert round(popt[0], 2) == 2.64\n\n    def test_fractional_order_model_5(self):\n        time_data = np.array([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n        current_data = np.array([0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [5.0, 5.0, 5.0, 5.0, 5.0, 5.0]))\n        assert round(popt[0], 2) == 3.33\n\n    def test_fractional_order_model_6(self):\n        time_data = np.array([0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60])\n        current_data = np.array([0, 0.6, 1.2, 1.8, 2.4, 3.0, 3.6, 4.2, 4.8, 5.4, 6.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [6.0, 6.0, 6.0, 6.0, 6.0, 6.0]))\n        assert round(popt[0], 2) == 4.0\n\n    def test_fractional_order_model_7(self):\n        time_data = np.array([0, 7, 14, 21, 28, 35, 42, 49, 56, 63, 70])\n        current_data = np.array([0, 0.7, 1.4, 2.1, 2.8, 3.5, 4.2, 4.9, 5.6, 6.3, 7.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [7.0, 7.0, 7.0, 7.0, 7.0, 7.0]))\n        assert round(popt[0], 2) == 4.67\n\n    def test_fractional_order_model_8(self):\n        time_data = np.array([0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80])\n        current_data = np.array([0, 0.8, 1.6, 2.4, 3.2, 4.0, 4.8, 5.6, 6.4, 7.2, 8.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [8.0, 8.0, 8.0, 8.0, 8.0, 8.0]))\n        assert round(popt[0], 2) == 5.34\n\n    def test_fractional_order_model_9(self):\n        time_data = np.array([0, 9, 18, 27, 36, 45, 54, 63, 72, 81, 90])\n        current_data = np.array([0, 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [9.0, 9.0, 9.0, 9.0, 9.0, 9.0]))\n        assert round(popt[0], 2) == 6.01\n\n    def test_fractional_order_model_10(self):\n        time_data = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n        current_data = np.array([0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])\n        popt, pcov = curve_fit(fractional_order_model, time_data, current_data, bounds=(0, [10.0, 10.0, 10.0, 10.0, 10.0, 10.0]))\n        assert round(popt[0], 2) == 6.68\n", "required_packages": ["pytest", "numpy", "scipy"]}
{"id": "37", "title": "Rename Files, Keep only Numbers", "description": "Given a folder path, rename all files within it by removing any letters from their names.  The file extension should be preserved. For example, if a file is named "image123ABC.jpg", it should be renamed to "123.jpg". Files with names containing no digits after removing letters should not be renamed.", "language": "python", "difficulty": "easy", "category": "Operation System", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nI want to write a python program that rename the files of a folder . \nplease remove all letters and keep the numbers\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testrename_files_in_folder:\n    def test_rename_files_in_folder_1(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file123abc.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/123.txt')\n\n", "llm_code": "import os\nimport re\n\ndef rename_files_in_folder(folder_path):\n    \"\"\"\n    Renames files in a folder by removing all letters from the filenames,\n    keeping only numbers and the file extension.\n\n    Args:\n        folder_path (str): The path to the folder containing the files to rename.\n    \"\"\"\n    for filename in os.listdir(folder_path):\n        if os.path.isfile(os.path.join(folder_path, filename)):\n            name, ext = os.path.splitext(filename)\n            new_name = re.sub(r'[^\\d]', '', name)\n            if new_name:\n                new_filename = new_name + ext\n                os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))", "correct_code": "import os\nimport re\n\ndef rename_files_in_folder(folder_path):\n    for filename in os.listdir(folder_path):\n        file_type = filename.split('.')[-1]\n        new_filename = re.sub(\"[A-Za-z]\", \"\", filename[:-len(file_type)]) + file_type\n        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))\n\n# Call the function with the path to the folder\n# rename_files_in_folder('/path/to/your/folder')", "test_code": "import pytest\n\nimport os\nimport re\n\nclass Testrename_files_in_folder:\n    def test_rename_files_in_folder_2(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file456def.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/456.txt')\n\n    def test_rename_files_in_folder_3(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file789ghi.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/789.txt')\n\n    def test_rename_files_in_folder_4(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file101112jkl.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/101112.txt')\n\n    def test_rename_files_in_folder_5(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file131415mno.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/131415.txt')\n\n    def test_rename_files_in_folder_6(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file161718pqr.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/161718.txt')\n\n    def test_rename_files_in_folder_7(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/.txt')\n\n    def test_rename_files_in_folder_8(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file123.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/123.txt')\n\n    def test_rename_files_in_folder_9(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file_1.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/_1.txt')\n\n    def test_rename_files_in_folder_10(self, tmpdir):\n        p = tmpdir.mkdir(\"sub\").join(\"file1234567890.abc-1.txt\")\n        p.write(\"content\")\n        rename_files_in_folder(str(tmpdir) + '/sub/')\n        assert os.path.isfile(str(tmpdir) + '/sub/1234567890.-1.txt')", "required_packages": ["os", "re", "pytest"]}
{"id": "4", "title": "UTF-8 to ASCII Conversion", "description": "Given a UTF-8 encoded string, write a function `utf8_to_ascii(s)` that converts it to a list of corresponding ASCII codes.  The function takes a single argument:", "language": "python", "difficulty": "easy", "category": "Software Engineering", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program that implements the function of converting a string from UTF-8 encoding to ASCII encoding. The requirements are as follows:\n\nInput a string (UTF-8 encoding).\nThe program will read the input string character by character and convert each character into the corresponding ASCII code.\nPrint out the converted ASCII codes one by one.\nYou can use an appropriate programming language to implement this function. Please note that multi-byte characters in UTF-8 encoding need to be specially handled to ensure correct conversion to the corresponding ASCII code. After calling the utf8_to_ascii function, an ASCII code list will be output, each element of which corresponds to the ASCII code of a character in the input string.\n\nFor example, if the input string is \"Hello World!\", after calling the utf8_to_ascii function, the following ASCII code list will be output:\n\n[72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]\nWhere the first element 72 corresponds to the ASCII code of the character H, the second element 101 corresponds to the ASCII code of the character e, and so on.\n\nThese ASCII codes can be further used for other operations, such as encryption, conversion, etc.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testutf8_to_ascii:\n    def test_hello_world(self):\n        assert utf8_to_ascii(\"Hello, World!\") == [72, 101, 108, 108, 111, 44, 32, 87, 111, 114, 108, 100, 33]\n\n", "llm_code": "def utf8_to_ascii(s):\n  \"\"\"\n  Converts a UTF-8 string to a list of ASCII codes.\n\n  Args:\n    s: The input string (UTF-8 encoded).\n\n  Returns:\n    A list of ASCII codes, where each element corresponds to the ASCII code\n    of a character in the input string.\n  \"\"\"\n  ascii_codes = []\n  for char in s:\n    ascii_codes.append(ord(char))\n  return ascii_codes", "correct_code": "def utf8_to_ascii(utf8_string):\n    # \u9a8c\u8bc1\u8f93\u5165\u5b57\u7b26\u4e32\u662f\u5426\u4e3a\u7a7a\n    if not utf8_string:\n        print(\"\u8f93\u5165\u5b57\u7b26\u4e32\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n        return None\n\n    result = []\n\n    try:\n        # \u904d\u5386\u8f93\u5165\u5b57\u7b26\u4e32\u7684\u6bcf\u4e2a\u5b57\u7b26\n        for i in range(len(utf8_string)):\n            if utf8_string[i] == '%' and i + 2 < len(utf8_string) and utf8_string[i + 1:i + 3].isalnum():\n                # \u5982\u679c\u9047\u5230\u4ee5%\u5f00\u5934\u768416\u8fdb\u5236\u5b57\u7b26\u7f16\u7801\uff0c\u5219\u8fdb\u884c\u89e3\u6790\n                hex_str = utf8_string[i + 1:i + 3]\n                ascii_code = int(hex_str, 16)\n                result.append(ascii_code)\n                i += 2\n            else:\n                # \u666e\u901a\u7684UTF-8\u5b57\u7b26\u76f4\u63a5\u8f6c\u6362\u4e3aASCII\u7801\n                ascii_code = ord(utf8_string[i])\n                result.append(ascii_code)\n    except IndexError:\n        print(\"\u8f93\u5165\u5b57\u7b26\u4e32\u683c\u5f0f\u9519\u8bef\uff01\")\n        return None\n    except ValueError:\n        print(\"\u8f93\u5165\u5b57\u7b26\u4e32\u5305\u542b\u975e\u6cd5\u7684\u5b57\u7b26\u7f16\u7801\uff01\")\n        return None\n    except Exception as e:\n        print(\"\u53d1\u751f\u672a\u77e5\u9519\u8bef\uff1a\", str(e))\n        return None\n\n    return result", "test_code": "\n\nclass Testutf8_to_ascii:\n    def test_empty_string(self):\n        assert utf8_to_ascii(\"\") == None\n\n    def test_invalid_hex_code(self):\n        assert utf8_to_ascii(\"Hello%20Wo%zz\") == None\n\n    def test_single_character(self):\n        assert utf8_to_ascii(\"A\") == [65]\n\n    def test_special_characters(self):\n        assert utf8_to_ascii(\"!@#$%^&*()_+-=\") == [33, 64, 35, 36, 37, 94, 38, 42, 40, 41, 95, 43, 45, 61]\n\n    def test_unicode_characters(self):\n        assert utf8_to_ascii(\"\\u2018\\u2019\\u201c\\u201d\") == [8216, 8217, 8220, 8221]\n\n    def test_long_string(self):\n        assert utf8_to_ascii(\"a\" * 1000) == [97] * 1000\n\n    def test_invalid_input_type(self):\n        assert utf8_to_ascii(123) == None\n\n    def test_invalid_input_encoding(self):\n        assert utf8_to_ascii(b\"Hello%20World%21\") == None\n", "required_packages": []}
{"id": "5", "title": "Extract Dates from Text", "description": "You are given a string `text`. Your task is to implement a Python function `find_dates(text)` that extracts all dates present in the string. The dates must adhere to the `YYYY-MM-DD` format, where the year is a four-digit number, and the month and day are two-digit numbers.  You must use regular expressions for date identification and return all matching dates as a list. If no valid dates are found, return an empty list.", "language": "python", "difficulty": "easy", "category": "Software Engineering", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program that implements a Python function find_dates(text), which accepts a string text as a parameter and returns all dates that appear in the string. The dates should be in the standard year-month-day (YYYY-MM-DD) format.\n\nRequirements:\n\nThe date must be in the standard year-month-day (YYYY-MM-DD) format.\n\nThe year in the date must be a four-digit number, and the month and day must be two-digit numbers.\n\nThe function should not use external resources such as web scraping or user input.\n\nThe function must use regular expressions to identify dates.\n\nThe function must return all dates that meet the requirements. If there are no dates that meet the requirements, it should return an empty list.\n\nExample:\n\npython\ntext = \"The event will take place on 2022-01-25 and the deadline is 2022-02-15.\"\nprint(find_dates(text))\n# output: ['2022-01-25', '2022-02-15']\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testfind_dates:\n    def test_case_1(self):\n        text = \"The event will take place on 2022-01-25 and the deadline is 2022-02-15.\"\n        expected_dates = [\"2022-01-25\", \"2022-02-15\"]\n        assert find_dates(text) == expected_dates\n\n", "llm_code": "import re\n\ndef find_dates(text):\n    \"\"\"\n    Finds all dates in the string in the format YYYY-MM-DD.\n\n    Args:\n        text: The string to search for dates in.\n\n    Returns:\n        A list of all dates found in the string.\n    \"\"\"\n    date_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n    dates = re.findall(date_pattern, text)\n    return dates", "correct_code": "import re\nimport datetime\n\n\ndef find_dates(text):\n    if not text:\n        return \"\u8f93\u5165\u7684\u6587\u672c\u4e3a\u7a7a\uff0c\u8bf7\u63d0\u4f9b\u6709\u6548\u7684\u6587\u672c\u5185\u5bb9\"\n\n    date_patterns = [\n        r\"\\b(\\d{4})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])\\b\",  # YYYY-MM-DD\n        r\"\\b(0[1-9]|1[0-2])/(0[1-9]|[12][0-9]|3[01])/(19|20)?\\d{2}\\b\",  # MM/DD/YYYY or M/D/YYYY\n        r\"\\b(0[1-9]|[12][0-9]|3[01])-(0[1-9]|1[0-2])-(19|20)?\\d{2}\\b\",  # DD-MM-YYYY or D-M-YYYY\n        r\"\\b(0[1-9]|[12][0-9]|3[01])\\s(January|February|March|April|May|June|July|August|September|October|November|December),?\\s(19|20)?\\d{2}\\b\"\n        # DD Month YYYY or D Month YYYY\n    ]\n    dates = []\n    for pattern in date_patterns:\n        dates.extend(re.findall(pattern, text))\n\n    formatted_dates = []\n    for date in dates:\n        if date[0]:  # \u5982\u679c\u5339\u914d\u5230\u4e86\u5e74\u4efd\n            year = date[0]\n        else:\n            year = \"20\" + date[3] if date[3] else \"\"  # \u5982\u679c\u6ca1\u6709\u5339\u914d\u5230\u5e74\u4efd\uff0c\u5219\u6839\u636e\u6a21\u5f0f\u4e2d\u7684\u5206\u7ec4\u786e\u5b9a\u5e74\u4efd\n\n        month = date[1].zfill(2)\n        day = date[2].zfill(2)\n\n        # \u68c0\u67e5\u65e5\u671f\u7684\u6709\u6548\u6027\n        try:\n            formatted_date = f\"{year}-{month}-{day}\"\n            _ = datetime.datetime.strptime(formatted_date, \"%Y-%m-%d\")\n            formatted_dates.append(formatted_date)\n        except ValueError:\n            pass\n\n    if not formatted_dates:\n        return \"\u672a\u627e\u5230\u6709\u6548\u65e5\u671f\"\n\n    return formatted_dates", "test_code": "import re\nimport datetime\n\n\nclass Testfind_dates:\n    def test_case_2(self):\n        text = \"Another possible date format is 2022-02-15.\"\n        expected_dates = ['2022-02-15']\n        assert find_dates(text) == expected_dates\n\n    def test_case_3(self):\n        text = \"And the third format is 01*01-*024.\"\n        expected_dates = \"\u672a\u627e\u5230\u6709\u6548\u65e5\u671f\"\n        assert find_dates(text) == expected_dates\n\n    def test_case_4(self):\n        text = \"Lastly, we have a date like 1 January 2025.\"\n        expected_dates = '\u672a\u627e\u5230\u6709\u6548\u65e5\u671f'\n        assert find_dates(text) == expected_dates\n\n    def test_case_5(self):\n        text = \"Invalid date formats: 2022-13-01, 31/12/2023, 01-01-2024\"\n        expected_dates = \"\u672a\u627e\u5230\u6709\u6548\u65e5\u671f\"\n        assert find_dates(text) == expected_dates\n\n    def test_case_6(self):\n        text = \"No dates in this text.\"\n        expected_dates = \"\u672a\u627e\u5230\u6709\u6548\u65e5\u671f\"\n        assert find_dates(text) == expected_dates\n\n    def test_case_7(self):\n        text = \"The event happened on 2020-12-25 and it was a great success.\"\n        expected_dates = [\"2020-12-25\"]\n        assert find_dates(text) == expected_dates\n\n    def test_case_8(self):\n        text = \"The due date for submission is 2022-06-30.\"\n        expected_dates = [\"2022-06-30\"]\n        assert find_dates(text) == expected_dates\n\n\n", "required_packages": ["re", "datetime"]}
{"id": "6", "title": "Memory Management Simulation", "description": "Implement a memory management simulation in Python. You'll work with a `Process` class, where each process has a unique ID (PID) and a piece of code represented as a list of instructions.  The operating system uses a `memory_map` (a list) to track memory allocation.", "language": "python", "difficulty": "medium", "category": "Operation System", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program that simulates the memory management of an operating system in Python code. A Process class is defined in the code, representing a process, each process has a unique process identifier (pid) and a piece of code (code). The operating system maintains a memory map, memory_map, to track the allocation of memory. In the example, two processes are created and added to the processes list. Then, by calling the allocate_memory function, memory is allocated for each process. Finally, by calling the run_processes function, all processes are simulated to run, and the memory occupied by the processes is released by calling the deallocate_memory function.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass TestProcess:\n    def test_successful_memory_allocation(self):\n        memory_map = [0] * 100\n        process = Process(pid=1, code=[1, 2, 3])\n\n        assert allocate_memory(memory_map, process) == True\n        assert process.memory is not None\n\n\n", "llm_code": "class Process:\n    def __init__(self, pid, code):\n        self.pid = pid\n        self.code = code\n        self.memory = None\n\ndef allocate_memory(memory_map, process):\n    required_memory = len(process.code)\n    for i in range(len(memory_map) - required_memory + 1):\n        if all(memory_map[i+j] == 0 for j in range(required_memory)):\n            for j in range(required_memory):\n                memory_map[i+j] = process.pid\n            process.memory = (i, required_memory)\n            return True\n    return False\n\ndef deallocate_memory(memory_map, process):\n    if process.memory:\n        start, size = process.memory\n        for i in range(start, start + size):\n            memory_map[i] = 0\n        process.memory = None\n\ndef run_processes(memory_map, processes):\n    for process in processes:\n        if process.memory:\n            print(f\"Running process {process.pid}...\")\n            # Simulate running the process\n            deallocate_memory(memory_map, process)\n            print(f\"Process {process.pid} finished and memory deallocated.\")\n        else:\n            print(f\"Process {process.pid} was not allocated memory.\")\n\nif __name__ == '__main__':\n    # Example usage:\n    memory_map = [0] * 100  # Simulate 100 units of memory\n\n    process1 = Process(pid=1, code=[1, 2, 3, 4, 5])\n    process2 = Process(pid=2, code=[6, 7, 8])\n    process3 = Process(pid=3, code=[9, 10, 11, 12])\n\n    processes = [process1, process2, process3]\n\n    for process in processes:\n        if allocate_memory(memory_map, process):\n            print(f\"Allocated memory for process {process.pid} at {process.memory}\")\n        else:\n            print(f\"Failed to allocate memory for process {process.pid}\")\n\n    print(\"Memory Map:\", memory_map)\n    run_processes(memory_map, processes)\n    print(\"Memory Map after running processes:\", memory_map)", "correct_code": "class Process:\n    def __init__(self, pid, code):\n        self.pid = pid\n        self.code = code\n        self.memory = None\n\ndef allocate_memory(memory_map, process):\n    if process.memory is not None:\n        raise ValueError(\"Process already has memory\")\n\n    for i in range(len(memory_map)):\n        if memory_map[i] == 0:\n            process.memory = i\n            for j in range(len(process.code)):\n                memory_map[i + j] = 1\n            return True\n\n    return False\n\ndef deallocate_memory(memory_map, process):\n    if process.memory is not None:\n        for i in range(len(process.code)):\n            memory_map[process.memory + i] = 0\n        process.memory = None\n\ndef run_processes(processes):\n    for process in processes:\n        print(f\"Running Process {process.pid} with code: {process.code}\")\n\n# \u521b\u5efa\u4e00\u4e2a\u7b80\u5355\u7684\u64cd\u4f5c\u7cfb\u7edf\nmemory_map = [0] * 100\nprocesses = []\n\n# \u521b\u5efa\u4e24\u4e2a\u8fdb\u7a0b\nprocess1 = Process(pid=1, code=[1, 2, 3])\nprocess2 = Process(pid=2, code=[4, 5, 6])\n\n# \u5c06\u8fdb\u7a0b\u6dfb\u52a0\u5230\u5217\u8868\nprocesses.append(process1)\nprocesses.append(process2)\n\n# \u5206\u914d\u5185\u5b58\nallocate_memory(memory_map, process1)\nallocate_memory(memory_map, process2)\n\n# \u8fd0\u884c\u8fdb\u7a0b\nrun_processes(processes)\n\n# \u91ca\u653e\u5185\u5b58\ndeallocate_memory(memory_map, process1)\ndeallocate_memory(memory_map, process2)", "test_code": "\n\nclass TestProcess:\n    def test_successful_allocation_multiple_processes(self):\n        memory_map = [0] * 100\n        process1 = Process(pid=1, code=[1, 2, 3])\n        process2 = Process(pid=2, code=[4, 5, 6])\n\n        assert allocate_memory(memory_map, process1) == True\n        assert allocate_memory(memory_map, process2) == True\n        assert process1.memory is not None\n        assert process2.memory is not None\n\n\n    def test_failed_memory_allocation(self):\n        memory_map = [1] * 100  # Memory is already full\n        process = Process(pid=1, code=[1, 2, 3])\n\n        assert allocate_memory(memory_map, process) == False\n        assert process.memory is None\n\n\n    def test_memory_deallocation(self):\n        memory_map = [0] * 100\n        process = Process(pid=1, code=[1, 2, 3])\n\n        allocate_memory(memory_map, process)\n        deallocate_memory(memory_map, process)\n\n        assert process.memory is None\n\n\n    def test_run_processes(self):\n        processes = [\n            Process(pid=1, code=[1, 2, 3]),\n            Process(pid=2, code=[4, 5, 6])\n        ]\n\n        run_processes(processes)\n        # Manual inspection of output\n\n\n    def test_deallocate_unallocated_memory(self):\n        memory_map = [0] * 100\n        process = Process(pid=1, code=[1, 2, 3])\n\n        deallocate_memory(memory_map, process)\n\n        assert process.memory is None\n\n\n    def test_run_empty_processes(self):\n        empty_processes = []\n        run_processes(empty_processes)\n        # Manual inspection of output\n\n\n    def test_allocate_full_memory(self):\n        full_memory_map = [0] * 100\n        full_process = Process(pid=1, code=[1] * 100)\n\n        assert allocate_memory(full_memory_map, full_process) == True\n        assert full_process.memory is not None\n\n\n    def test_continuous_allocation_deallocation(self):\n        continuous_memory_map = [0] * 100\n        continuous_process = Process(pid=1, code=[1, 2, 3])\n\n        assert allocate_memory(continuous_memory_map, continuous_process) == True\n        assert continuous_process.memory is not None\n\n        deallocate_memory(continuous_memory_map, continuous_process)\n\n        assert continuous_process.memory is None\n", "required_packages": []}
{"id": "7", "title": "Top K Frequent Words from HTML", "description": "Given an HTML string `html` and an integer `k`, return the top `k` most frequent words and their counts.", "language": "python", "difficulty": "medium", "category": "Front-End", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program to implement the following problem description:\nGiven an HTML text containing multiple English sentences, write a function get_top_k_words_from_html(html, k) that returns the top k words with the highest frequency of occurrence.\n\nWrite a function get_top_k_words_from_html(html, k), where the parameter html is a string containing HTML tags, and k is a positive integer. The function should return a list containing the top k words with the highest frequency of occurrence and their frequencies, sorted in descending order of frequency.\n\nExamples:\nInput: \"<p>We are the world, we are the children.</p> <p>We are the ones who make a brighter day.</p> <p>So let's start giving.</p>\"\nOutput: [('we', 3), ('are', 3), ('the', 3)]\n\nInput: \"<p>The quick brown fox jumps over the lazy dog.</p> <p>The quick brown fox jumps over the lazy dog.</p>\"\nOutput: [('the', 4), ('brown', 2), ('quick', 2)]\n\nNote:\n\nWords are case-insensitive, i.e., \"The\" and \"the\" are considered the same word.\nA word is defined as a string composed of letters and numbers, excluding punctuation.\nThe returned list should include all the top k words with the same frequency of occurrence and their frequencies.\nYou can use libraries to parse HTML text and use standard library functions or modules to assist in solving the problem.\nPlease implement the function get_top_k_words_from_html(html, k) to solve this problem.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testget_top_k_words_from_html:\n    def test_empty_html(self):\n        html = \"<html><body></body></html>\"\n        assert get_top_k_words_from_html(html, 5) == []\n\n", "llm_code": "from bs4 import BeautifulSoup\nimport re\nfrom collections import Counter\n\ndef get_top_k_words_from_html(html, k):\n    \"\"\"\n    Returns the top k words with the highest frequency of occurrence in the given HTML text.\n\n    Args:\n        html (str): A string containing HTML tags.\n        k (int): A positive integer.\n\n    Returns:\n        list: A list containing the top k words with the highest frequency of occurrence and their frequencies, sorted in descending order of frequency.\n    \"\"\"\n    soup = BeautifulSoup(html, 'html.parser')\n    text = soup.get_text()\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    top_k_words = word_counts.most_common(k)\n    return top_k_words", "correct_code": "import re\nfrom collections import Counter\nfrom bs4 import BeautifulSoup\n\n\ndef get_top_k_words_from_html(html, k):\n    # \u5b9a\u4e49\u9700\u8981\u6392\u9664\u7684\u5355\u8bcd\u5217\u8868\n    exclude_list = ['this','is','are','a', 'an', 'the', 'and', 'or', 'in', 'on', 'at', 'to', 'of', 'for', 'with', 'by', 'from']\n\n    try:\n        # \u89e3\u6790HTML\u6587\u672c\n        soup = BeautifulSoup(html, 'lxml')\n\n        # \u83b7\u53d6\u6240\u6709\u6587\u672c\u5185\u5bb9\n        text = soup.get_text()\n\n        # \u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u5c0f\u5199\uff0c\u5e76\u4f7f\u7528\u6b63\u5219\u8868\u8fbe\u5f0f\u63d0\u53d6\u5355\u8bcd\n\n        lower=text.lower()\n        words = re.findall(r'\\b(?<!-)(?!' + '|'.join(exclude_list) + r')\\w+(?<!-)\\b', lower, flags=re.UNICODE)\n\n        # \u4f7f\u7528Counter\u7edf\u8ba1\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\n        word_counts = Counter(words)\n\n        # \u83b7\u53d6\u51fa\u73b0\u6b21\u6570\u6700\u591a\u7684\u524dk\u4e2a\u5355\u8bcd\u53ca\u5176\u51fa\u73b0\u6b21\u6570\n        top_k_words = word_counts.most_common(k)\n\n        return top_k_words\n\n    except Exception as e:\n        print(\"Error occurred:\", str(e))\n        return None", "test_code": "import re\nfrom collections import Counter\nfrom bs4 import BeautifulSoup\n\n\nclass Testget_top_k_words_from_html:\n    def test_basic_html(self):\n        html = \"<html><body>This is a simple HTML text. Hello world!</body></html>\"\n        assert get_top_k_words_from_html(html, 3) == [('simple', 1), ('html', 1), ('text', 1)]\n\n    def test_html_with_tags(self):\n        html = \"<html><body><h1>Title</h1><p> is a paragraph.</p></body></html>\"\n        assert get_top_k_words_from_html(html, 4) == [('title', 1), ('paragraph', 1)]\n\n    def test_html_with_special_characters(self):\n        html = \"<html><body>Encoding: &#1632;&#1633;&#1634;</body></html>\"\n        assert get_top_k_words_from_html(html, 3) == [('encoding', 1), ('\u0660\u0661\u0662', 1)]\n\n    def test_html_with_unicode_characters(self):\n        html = \"<html><body>Unicode: \u00e0\u00e9\u00ee\u0151\u0171</body></html>\"\n        assert get_top_k_words_from_html(html, 4) == [('unicode', 1), ('\u00e0\u00e9\u00ee\u0151\u0171', 1)]\n\n    def test_html_with_duplicate_words(self):\n        html = \"<html><body>Repeated words test. This is a test repeated words.</body></html>\"\n        assert get_top_k_words_from_html(html, 4) == [('repeated', 2), ('words', 2), ('test', 2)]\n\n    def test_large_html(self):\n        # Test with a large HTML content\n        html = \"<html><body>\" + \"word1 \" * 1000 + \"</body></html>\"\n        assert get_top_k_words_from_html(html, 1) == [('word1', 1000)]\n\n\n    def test_html_with_numbers(self):\n        html = \"<html><body>Numbers: 123 456 789</body></html>\"\n        assert get_top_k_words_from_html(html, 3) == [('numbers', 1), ('123', 1), ('456', 1)]\n\n\n    def test_html_with_unicode_characters_and_numbers(self):\n        html = \"<html><body>Unicode and numbers: \u00e0\u00e9\u00ee\u0151\u0171 12345</body></html>\"\n        assert get_top_k_words_from_html(html, 4) == [('unicode', 1), ('numbers', 1), ('\u00e0\u00e9\u00ee\u0151\u0171', 1), ('12345', 1)]\n\n\n\n", "required_packages": ["re", "collections", "bs4"]}
{"id": "8", "title": "Temperature Data Analysis", "description": "You are given a multi-line string containing temperature data. Each line represents a city and its temperature in Celsius. Your task is to implement four functions:", "language": "python", "difficulty": "easy", "category": "Data Science", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program to complete the task: Meteorological Data Analysis\n\nWrite a program to analyze and process temperature data.\n\nRequirements:\n\nWrite a function extract_temperatures_from_text(text: str) -> List[float], which takes a text string as a parameter, extracts temperature data from the text, and returns it in the form of a list. Each line in the file contains a temperature value in Celsius.\n\nWrite a function calculate_average_temperature(temperatures: List[float]) -> float, which takes a list of temperature data as a parameter, calculates the average temperature, and returns it.\n\nWrite a function find_highest_temperature(temperatures: List[float]) -> float, which takes a list of temperature data as a parameter, finds the highest temperature in it, and returns it.\n\nWrite a function find_lowest_temperature(temperatures: List[float]) -> float, which takes a list of temperature data as a parameter, finds the lowest temperature in it, and returns it.\n\nUse case:\n\npython\ntext = \"\"\"\nBeijing, -4\u2103\nShanghai, 3\u2103\nGuangzhou, 12\u2103\nChongqing, 8\u2103\n\"\"\"\n\ntemperatures = extract_temperatures_from_text(text)\naverage_temp = calculate_average_temperature(temperatures)\nhighest_temp = find_highest_temperature(temperatures)\nlowest_temp = find_lowest_temperature(temperatures)\n\nprint(\"Extracted temperature data:\", temperatures)\nprint(\"Average temperature:\", average_temp)\nprint(\"Highest temperature:\", highest_temp)\nprint(\"Lowest temperature:\", lowest_temp)\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testextract_temperatures_from_text:\n    def test_extract_temperatures_from_text_with_temperatures(self):\n        text = \"\u5317\u4eac\uff0c-4\u2103\\n\u4e0a\u6d77\uff0c3\u2103\\n\u5e7f\u5dde\uff0c12\u2103\\n\u91cd\u5e86\uff0c8\u2103\"\n        cities, temperatures = extract_temperatures_from_text(text)\n        assert cities == [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\", \"\u91cd\u5e86\"]\n        assert temperatures == [-4.0, 3.0, 12.0, 8.0]\n\n", "llm_code": "from typing import List\n\ndef extract_temperatures_from_text(text: str) -> List[float]:\n    \"\"\"\n    Extracts temperature data from the text.\n    Each line in the file contains a temperature value in Celsius.\n    \"\"\"\n    temperatures = []\n    for line in text.strip().split(\"\\n\"):\n        try:\n            temp_str = line.split(\",\")[1].replace(\"\u2103\", \"\").strip()\n            temperatures.append(float(temp_str))\n        except (IndexError, ValueError):\n            continue \n    return temperatures\n\ndef calculate_average_temperature(temperatures: List[float]) -> float:\n    \"\"\"\n    Calculates the average temperature.\n    \"\"\"\n    if not temperatures:\n        return 0.0\n    return sum(temperatures) / len(temperatures)\n\ndef find_highest_temperature(temperatures: List[float]) -> float:\n    \"\"\"\n    Finds the highest temperature.\n    \"\"\"\n    if not temperatures:\n        return float('-inf')\n    return max(temperatures)\n\ndef find_lowest_temperature(temperatures: List[float]) -> float:\n    \"\"\"\n    Finds the lowest temperature.\n    \"\"\"\n    if not temperatures:\n        return float('inf')\n    return min(temperatures)", "correct_code": "from typing import List, Tuple\n\n\ndef extract_temperatures_from_text(text: str) -> Tuple[List[str], List[float]]:\n    cities = []\n    temperatures = []\n    lines = text.strip().split('\\n')\n    for line in lines:\n        city_temperature = line.split('\uff0c')\n        if len(city_temperature) == 2:\n            city, temperature = city_temperature\n            temperature = float(temperature.replace('\u2103', ''))\n            cities.append(city)\n            temperatures.append(temperature)\n        else:\n            return [], []\n    return cities, temperatures\n\ndef calculate_average_temperature(temperatures: List[float]) -> float:\n    total_temperature = sum(temperatures)\n    average_temperature = total_temperature / len(temperatures)\n    return average_temperature\n\ndef find_highest_temperature(cities: List[str], temperatures: List[float]) -> Tuple[float, str]:\n    if not temperatures:\n        return 0, \"\u65e0\"\n    index = temperatures.index(max(temperatures))\n    highest_temperature = temperatures[index]\n    city = cities[index]\n    return highest_temperature, city\n\ndef find_lowest_temperature(cities: List[str], temperatures: List[float]) -> Tuple[float, str]:\n    if not temperatures:\n        return 0, \"\u65e0\"\n    index = temperatures.index(min(temperatures))\n    lowest_temperature = temperatures[index]\n    city = cities[index]\n    return lowest_temperature, city", "test_code": "from typing import List, Tuple\n\n\nclass Testextract_temperatures_from_text:\n    def test_extract_temperatures_from_text_without_temperatures(self):\n        text = \"\u5317\u4eac\\n\u4e0a\u6d77\\n\u5e7f\u5dde\\n\u91cd\u5e86\"\n        cities, temperatures = extract_temperatures_from_text(text)\n        assert cities == []\n        assert temperatures == []\n\n    def test_calculate_average_temperature(self):\n        temperatures = [10.0, 20.0, 30.0]\n        assert calculate_average_temperature(temperatures) == 20.0\n\n    def test_find_highest_temperature(self):\n        cities = [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\", \"\u91cd\u5e86\"]\n        temperatures = [-4.0, 3.0, 12.0, 8.0]\n        assert find_highest_temperature(cities, temperatures) == (12.0, \"\u5e7f\u5dde\")\n\n    def test_find_lowest_temperature(self):\n        cities = [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\", \"\u91cd\u5e86\"]\n        temperatures = [-4.0, 3.0, 12.0, 8.0]\n        assert find_lowest_temperature(cities, temperatures) == (-4.0, \"\u5317\u4eac\")\n\n    def test_extract_temperatures_from_text_with_single_data(self):\n        text = \"\u5317\u4eac\uff0c-4\u2103\"\n        cities, temperatures = extract_temperatures_from_text(text)\n        assert cities == [\"\u5317\u4eac\"]\n        assert temperatures == [-4.0]\n\n    def test_extract_temperatures_from_text_with_cities_only(self):\n        text = \"\u5317\u4eac\\n\u4e0a\u6d77\\n\u5e7f\u5dde\\n\u91cd\u5e86\"\n        cities, temperatures = extract_temperatures_from_text(text)\n        assert cities == []\n        assert temperatures == []\n\n    def test_calculate_average_temperature_with_single_temperature(self):\n        temperatures = [10.0]\n        assert calculate_average_temperature(temperatures) == 10.0\n\n    def test_find_highest_temperature_with_single_temperature(self):\n        cities = [\"\u5317\u4eac\"]\n        temperatures = [-4.0]\n        assert find_highest_temperature(cities, temperatures) == (-4.0, \"\u5317\u4eac\")\n\n    def test_find_lowest_temperature_with_single_temperature(self):\n        cities = [\"\u5317\u4eac\"]\n        temperatures = [-4.0]\n        assert find_lowest_temperature(cities, temperatures) == (-4.0, \"\u5317\u4eac\")\n\n    def test_extract_temperatures_from_text_with_duplicate_temperatures(self):\n        text = \"\u5317\u4eac\uff0c-4\u2103\\n\u4e0a\u6d77\uff0c3\u2103\\n\u5e7f\u5dde\uff0c12\u2103\\n\u91cd\u5e86\uff0c8\u2103\\n\u6210\u90fd\uff0c12\u2103\"\n        cities, temperatures = extract_temperatures_from_text(text)\n        assert cities == [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\", \"\u91cd\u5e86\", \"\u6210\u90fd\"]\n        assert temperatures == [-4.0, 3.0, 12.0, 8.0, 12.0]\n\n    def test_extract_temperatures_from_text_with_decimal_temperatures(self):\n        text = \"\u5317\u4eac\uff0c-4.5\u2103\\n\u4e0a\u6d77\uff0c3.2\u2103\\n\u5e7f\u5dde\uff0c12.7\u2103\\n\u91cd\u5e86\uff0c8.9\u2103\"\n        cities, temperatures = extract_temperatures_from_text(text)\n        assert cities == [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\", \"\u91cd\u5e86\"]\n        assert temperatures == [-4.5, 3.2, 12.7, 8.9]\n\n", "required_packages": ["typing"]}
{"id": "9", "title": "Count HTML Tags", "description": "Given a valid HTML string, your task is to write a function `count_html_tags(html)` that counts and returns the total number of HTML tags present in the string.  An HTML tag is defined as a sequence of lowercase letters enclosed within angle brackets `<` and `>`.  You can assume the input HTML string is well-formed, and no error handling is needed.  For example,  if `html = \"<p>This is a paragraph.</p><div>This is a div.</div>\"`, the function should return 2.", "language": "python", "difficulty": "easy", "category": "Front-End", "llm_prompt": "Your task is to generate python code to solve the following problem. The generated code must be placed between the ```python and ```, and only one code block is allowed: \nWrite a program, a function count_html_tags(html), which accepts an HTML string as a parameter and returns the number of HTML tags contained in the string.\n\nRequirements:\n\nHTML tags are surrounded by angle brackets < and >, with the tag name inside the brackets.\nThe tag name consists of lowercase letters and does not contain spaces or other special characters.\nAssume that the input HTML string is valid, no error handling is required.\n\nYou need to follow the function names or class names in the test cases. The generated code should not contain any test cases: \nclass Testcount_html_tags:\n    def test_empty_string(self):\n        html = \"\"\n        tag_count, max_nested_depth = count_html_tags(html)\n        assert tag_count == 0\n        assert max_nested_depth == 0\n\n", "llm_code": "import re\n\ndef count_html_tags(html):\n    \"\"\"\n    Counts the number of HTML tags in a given HTML string.\n\n    Args:\n        html: The HTML string.\n\n    Returns:\n        The number of HTML tags in the string.\n    \"\"\"\n    tags = re.findall(r\"<[a-z]+>\", html)\n    return len(tags)", "correct_code": "import re\n\n\ndef count_html_tags(html):\n    pattern = r'<\\s*([a-zA-Z]+)[^>]*>|<\\s*/\\s*([a-zA-Z]+)\\s*>'\n    matches = re.findall(pattern, html)\n\n    tag_count = 0\n    nested_tags = []\n    max_nested_depth = 0\n\n    for opening_tag, closing_tag in matches:\n        if opening_tag:\n            nested_tags.append(opening_tag.lower())\n            tag_count += 1\n            max_nested_depth = max(max_nested_depth, len(nested_tags))\n        elif nested_tags and nested_tags[-1] == closing_tag.lower():\n            nested_tags.pop()\n            tag_count += 1\n\n    return tag_count, max_nested_depth", "test_code": "import re\n\n\nclass Testcount_html_tags:\n    def test_single_tag(self):\n        html = \"<div></div>\"\n        tag_count, max_nested_depth = count_html_tags(html)\n        assert tag_count == 2\n        assert max_nested_depth == 1\n\n    def test_nested_tags(self):\n        html = \"<div><p><span></span></p></div>\"\n        tag_count, max_nested_depth = count_html_tags(html)\n        assert tag_count == 6\n        assert max_nested_depth == 3\n\n    def test_mismatched_closing_tag(self):\n        html = \"<div></span>\"\n        tag_count, max_nested_depth = count_html_tags(html)\n        assert tag_count == 1\n        assert max_nested_depth == 1\n\n    def test_case_sensitive(self):\n        html = \"<DIV><P><SPAN></span></P></div>\"\n        tag_count, max_nested_depth = count_html_tags(html)\n        assert tag_count == 6\n        assert max_nested_depth == 3\n\n    def test_special_characters(self):\n        html = \"<p>This is some text with &lt;strong&gt; tags.</p>\"\n        tag_count, max_nested_depth = count_html_tags(html)\n        assert tag_count == 2\n\n    def test_unbalanced_tags(self):\n        html = \"<div><p></div></p>\"\n        result = count_html_tags(html)\n        assert result == (3, 2)", "required_packages": ["re"]}
